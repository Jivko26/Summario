{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtopeIR34kV6",
        "outputId": "88bef752-7463-462c-81a2-0a7e6041231a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting OpenNMT-py\n",
            "  Downloading OpenNMT_py-3.4.3-py3-none-any.whl (257 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/257.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m194.6/257.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.3/257.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch<2.2,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.1.0+cu118)\n",
            "Collecting configargparse (from OpenNMT-py)\n",
            "  Downloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\n",
            "Collecting ctranslate2<4,>=3.17 (from OpenNMT-py)\n",
            "  Downloading ctranslate2-3.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.8/36.8 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.3 in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.14.1)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (2.2.5)\n",
            "Collecting waitress (from OpenNMT-py)\n",
            "  Downloading waitress-2.1.2-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyonmttok<2,>=1.35 (from OpenNMT-py)\n",
            "  Downloading pyonmttok-1.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (6.0.1)\n",
            "Collecting sacrebleu (from OpenNMT-py)\n",
            "  Downloading sacrebleu-2.3.2-py3-none-any.whl (119 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.7/119.7 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz (from OpenNMT-py)\n",
            "  Downloading rapidfuzz-3.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from OpenNMT-py)\n",
            "  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fasttext-wheel (from OpenNMT-py)\n",
            "  Downloading fasttext_wheel-0.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (3.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from OpenNMT-py) (1.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.17->OpenNMT-py) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.17->OpenNMT-py) (1.23.5)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.59.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.5.1)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.3->OpenNMT-py) (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.2,>=2.0.1->OpenNMT-py) (2.1.0)\n",
            "Collecting pybind11>=2.2 (from fasttext-wheel->OpenNMT-py)\n",
            "  Downloading pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.7/227.7 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->OpenNMT-py) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->OpenNMT-py) (8.1.7)\n",
            "Collecting portalocker (from sacrebleu->OpenNMT-py)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->OpenNMT-py)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu->OpenNMT-py) (4.9.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (4.66.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (1.10.13)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (23.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy->OpenNMT-py) (3.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.3->OpenNMT-py) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<2.2,>=2.0.1->OpenNMT-py) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3->OpenNMT-py) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->OpenNMT-py) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy->OpenNMT-py) (0.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.2,>=2.0.1->OpenNMT-py) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.3->OpenNMT-py) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.3->OpenNMT-py) (3.2.2)\n",
            "Installing collected packages: waitress, rapidfuzz, pyonmttok, pybind11, pyahocorasick, portalocker, ctranslate2, configargparse, colorama, sacrebleu, fasttext-wheel, OpenNMT-py\n",
            "Successfully installed OpenNMT-py-3.4.3 colorama-0.4.6 configargparse-1.7 ctranslate2-3.22.0 fasttext-wheel-0.9.2 portalocker-2.8.2 pyahocorasick-2.0.0 pybind11-2.11.1 pyonmttok-1.37.1 rapidfuzz-3.5.2 sacrebleu-2.3.2 waitress-2.1.2\n"
          ]
        }
      ],
      "source": [
        "# Install OpenNMT-py 3.x\n",
        "!pip3 install OpenNMT-py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pl7SV2vrjk3E",
        "outputId": "cf860c80-ad33-4111-cd95-ad21f1737083"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/nmt/nmt\n",
            "Cloning into 'MT-Preparation'...\n",
            "remote: Enumerating objects: 248, done.\u001b[K\n",
            "remote: Counting objects: 100% (248/248), done.\u001b[K\n",
            "remote: Compressing objects: 100% (139/139), done.\u001b[K\n",
            "remote: Total 248 (delta 123), reused 193 (delta 97), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (248/248), 64.32 KiB | 5.85 MiB/s, done.\n",
            "Resolving deltas: 100% (123/123), done.\n"
          ]
        }
      ],
      "source": [
        "# Create a directory and clone the Github MT-Preparation repository\n",
        "!mkdir -p nmt\n",
        "%cd nmt\n",
        "!git clone https://github.com/ymoslem/MT-Preparation.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUMF5SPNkaBI",
        "outputId": "cc4fb1e3-2add-4738-80d7-35e77dc04a58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset downloaded and extracted successfully in the current directory.\n",
            "Extracted files:\n",
            "EUbookshop.en-nl.en\n",
            "EUbookshop.en-nl.nl\n",
            "EUbookshop.en-nl.ids\n",
            "README\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "\n",
        "# Define the URL of the dataset\n",
        "url = \"https://opus.nlpl.eu/download.php?f=EUbookshop/v2/moses/en-nl.txt.zip\"\n",
        "\n",
        "# Send an HTTP GET request to download the dataset\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    # Create a file-like object from the response content\n",
        "    with zipfile.ZipFile(io.BytesIO(response.content)) as zip_file:\n",
        "        # Extract all the files in the zip archive to the current working directory (Colab environment)\n",
        "        zip_file.extractall()\n",
        "        extracted_files = zip_file.namelist()\n",
        "    print(\"Dataset downloaded and extracted successfully in the current directory.\")\n",
        "    print(\"Extracted files:\")\n",
        "    for file_name in extracted_files:\n",
        "        print(file_name)\n",
        "else:\n",
        "    print(\"Failed to download the dataset. Status code:\", response.status_code)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lci932ZxjmU0",
        "outputId": "2b2e286a-c370-4dfc-d441-2a8ba574e4c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r MT-Preparation/requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r MT-Preparation/requirements.txt (line 2)) (1.5.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r MT-Preparation/requirements.txt (line 3)) (0.1.99)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r MT-Preparation/requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r MT-Preparation/requirements.txt (line 2)) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->-r MT-Preparation/requirements.txt (line 2)) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# Install the requirements\n",
        "!pip3 install -r MT-Preparation/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmvXPpvYLzTu",
        "outputId": "f0b64770-a134-41f8-f015-c4a0e79789d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EUbookshop.en-nl.en  EUbookshop.en-nl.ids  EUbookshop.en-nl.nl\tMT-Preparation\tREADME\n"
          ]
        }
      ],
      "source": [
        "!ls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isIHuZp9j6N8",
        "outputId": "3772ebcb-8181-4909-ee21-7b08e2584a5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframe shape (rows, columns): (5964564, 2)\n",
            "--- Rows with Empty Cells Deleted\t--> Rows: 5964564\n",
            "--- Duplicates Deleted\t\t\t--> Rows: 5402094\n",
            "--- Source-Copied Rows Deleted\t\t--> Rows: 5402094\n",
            "--- Too Long Source/Target Deleted\t--> Rows: 4670136\n",
            "--- HTML Removed\t\t\t--> Rows: 4670136\n",
            "--- Rows will remain in true-cased\t--> Rows: 4670136\n",
            "--- Rows with Empty Cells Deleted\t--> Rows: 4670133\n",
            "--- Rows Shuffled\t\t\t--> Rows: 4670133\n",
            "--- Source Saved: EUbookshop.en-nl.en-filtered.en\n",
            "--- Target Saved: EUbookshop.en-nl.nl-filtered.nl\n"
          ]
        }
      ],
      "source": [
        "# Filter the dataset\n",
        "# Arguments: source file, target file, source language, target language\n",
        "!python3 MT-Preparation/filtering/filter.py EUbookshop.en-nl.en EUbookshop.en-nl.nl en nl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XUZBYfvpQv8",
        "outputId": "b4ab3019-59fe-454c-d88f-a2f3fa858234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1-train_bpe.py\t1-train_unigram.py  2-subword.py  3-desubword.py\n"
          ]
        }
      ],
      "source": [
        "!ls MT-Preparation/subwording/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTPWYQCIpbKF",
        "outputId": "94ca7ad0-3188-4e17-fae7-a2c756462e14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/content/nmt/nmt/EUbookshop.en-nl.en-filtered.en --model_prefix=source --vocab_size=10000 --hard_vocab_limit=false --split_digits=true --input_sentence_size=1000000\n",
            "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: /content/nmt/nmt/EUbookshop.en-nl.en-filtered.en\n",
            "  input_format: \n",
            "  model_prefix: source\n",
            "  model_type: UNIGRAM\n",
            "  vocab_size: 10000\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 0.9995\n",
            "  input_sentence_size: 1000000\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 1\n",
            "  pretokenization_delimiter: \n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  hard_vocab_limit: 0\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 0\n",
            "  bos_id: 1\n",
            "  eos_id: 2\n",
            "  pad_id: -1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "  enable_differential_privacy: 0\n",
            "  differential_privacy_noise_level: 0\n",
            "  differential_privacy_clipping_threshold: 0\n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(183) LOG(INFO) Loading corpus: /content/nmt/nmt/EUbookshop.en-nl.en-filtered.en\n",
            "trainer_interface.cc(145) LOG(INFO) Loaded 1000000 lines\n",
            "trainer_interface.cc(145) LOG(INFO) Loaded 2000000 lines\n",
            "trainer_interface.cc(378) LOG(WARNING) Found too long line (4681 > 4192).\n",
            "trainer_interface.cc(380) LOG(WARNING) Too long lines are skipped in the training.\n",
            "trainer_interface.cc(381) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
            "trainer_interface.cc(145) LOG(INFO) Loaded 3000000 lines\n",
            "trainer_interface.cc(145) LOG(INFO) Loaded 4000000 lines\n",
            "trainer_interface.cc(409) LOG(INFO) Sampled 1000000 sentences from 4670131 sentences.\n",
            "trainer_interface.cc(414) LOG(INFO) Skipped 2 too long sentences.\n",
            "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(537) LOG(INFO) all chars count=153091609\n",
            "trainer_interface.cc(548) LOG(INFO) Done: 99.9512% characters are covered.\n",
            "trainer_interface.cc(558) LOG(INFO) Alphabet size=87\n",
            "trainer_interface.cc(559) LOG(INFO) Final character coverage=0.999512\n",
            "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 1000000 sentences.\n",
            "unigram_model_trainer.cc(222) LOG(INFO) Making suffix array...\n",
            "unigram_model_trainer.cc(226) LOG(INFO) Extracting frequent sub strings... node_num=82531059\n",
            "unigram_model_trainer.cc(274) LOG(INFO) Initialized 600302 seed sentencepieces\n",
            "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 1000000\n",
            "trainer_interface.cc(608) LOG(INFO) Done! 659483\n",
            "unigram_model_trainer.cc(564) LOG(INFO) Using 659483 sentences for EM training\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=167870 obj=11.7655 num_tokens=2501195 num_tokens/piece=14.8996\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=150046 obj=8.73429 num_tokens=2501735 num_tokens/piece=16.6731\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=112521 obj=8.71764 num_tokens=2543382 num_tokens/piece=22.6036\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=112481 obj=8.71294 num_tokens=2544737 num_tokens/piece=22.6237\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=84356 obj=8.73042 num_tokens=2598503 num_tokens/piece=30.804\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=84355 obj=8.72665 num_tokens=2598432 num_tokens/piece=30.8035\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=63266 obj=8.75402 num_tokens=2662001 num_tokens/piece=42.0763\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=63266 obj=8.74873 num_tokens=2662092 num_tokens/piece=42.0778\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=47449 obj=8.78743 num_tokens=2733223 num_tokens/piece=57.6034\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=47448 obj=8.78399 num_tokens=2733177 num_tokens/piece=57.6036\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=35586 obj=8.83634 num_tokens=2811815 num_tokens/piece=79.0146\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=35586 obj=8.82649 num_tokens=2812289 num_tokens/piece=79.028\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=26689 obj=8.90191 num_tokens=2897268 num_tokens/piece=108.557\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=26689 obj=8.88854 num_tokens=2897345 num_tokens/piece=108.56\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=20016 obj=8.98767 num_tokens=2991374 num_tokens/piece=149.449\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=20016 obj=8.96974 num_tokens=2991503 num_tokens/piece=149.456\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=15012 obj=9.09981 num_tokens=3092025 num_tokens/piece=205.97\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=15012 obj=9.07689 num_tokens=3092156 num_tokens/piece=205.979\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=11259 obj=9.24117 num_tokens=3196269 num_tokens/piece=283.886\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=11259 obj=9.21117 num_tokens=3196875 num_tokens/piece=283.94\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=11000 obj=9.22409 num_tokens=3208339 num_tokens/piece=291.667\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=11000 obj=9.22122 num_tokens=3208544 num_tokens/piece=291.686\n",
            "trainer_interface.cc(686) LOG(INFO) Saving model: source.model\n",
            "trainer_interface.cc(698) LOG(INFO) Saving vocabs: source.vocab\n",
            "Done, training a SentencepPiece model for the Source finished successfully!\n",
            "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/content/nmt/nmt/EUbookshop.en-nl.nl-filtered.nl --model_prefix=target --vocab_size=10000 --hard_vocab_limit=false --split_digits=true --input_sentence_size=1000000\n",
            "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: /content/nmt/nmt/EUbookshop.en-nl.nl-filtered.nl\n",
            "  input_format: \n",
            "  model_prefix: target\n",
            "  model_type: UNIGRAM\n",
            "  vocab_size: 10000\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 0.9995\n",
            "  input_sentence_size: 1000000\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 4192\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 1\n",
            "  pretokenization_delimiter: \n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  hard_vocab_limit: 0\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 0\n",
            "  bos_id: 1\n",
            "  eos_id: 2\n",
            "  pad_id: -1\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "  enable_differential_privacy: 0\n",
            "  differential_privacy_noise_level: 0\n",
            "  differential_privacy_clipping_threshold: 0\n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(183) LOG(INFO) Loading corpus: /content/nmt/nmt/EUbookshop.en-nl.nl-filtered.nl\n",
            "trainer_interface.cc(145) LOG(INFO) Loaded 1000000 lines\n",
            "trainer_interface.cc(145) LOG(INFO) Loaded 2000000 lines\n",
            "trainer_interface.cc(378) LOG(WARNING) Found too long line (4401 > 4192).\n",
            "trainer_interface.cc(380) LOG(WARNING) Too long lines are skipped in the training.\n",
            "trainer_interface.cc(381) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
            "trainer_interface.cc(145) LOG(INFO) Loaded 3000000 lines\n",
            "trainer_interface.cc(145) LOG(INFO) Loaded 4000000 lines\n",
            "trainer_interface.cc(409) LOG(INFO) Sampled 1000000 sentences from 4670132 sentences.\n",
            "trainer_interface.cc(414) LOG(INFO) Skipped 1 too long sentences.\n",
            "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(537) LOG(INFO) all chars count=166905472\n",
            "trainer_interface.cc(548) LOG(INFO) Done: 99.9518% characters are covered.\n",
            "trainer_interface.cc(558) LOG(INFO) Alphabet size=89\n",
            "trainer_interface.cc(559) LOG(INFO) Final character coverage=0.999518\n",
            "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 1000000 sentences.\n",
            "unigram_model_trainer.cc(222) LOG(INFO) Making suffix array...\n",
            "unigram_model_trainer.cc(226) LOG(INFO) Extracting frequent sub strings... node_num=89101017\n",
            "unigram_model_trainer.cc(274) LOG(INFO) Initialized 1000089 seed sentencepieces\n",
            "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 1000000\n",
            "trainer_interface.cc(608) LOG(INFO) Done! 832618\n",
            "unigram_model_trainer.cc(564) LOG(INFO) Using 832618 sentences for EM training\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=260690 obj=12.1889 num_tokens=2830487 num_tokens/piece=10.8577\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=218791 obj=8.94031 num_tokens=2836199 num_tokens/piece=12.9631\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=164031 obj=8.91659 num_tokens=2882696 num_tokens/piece=17.5741\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=163772 obj=8.9093 num_tokens=2883999 num_tokens/piece=17.6098\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=122820 obj=8.93291 num_tokens=2953636 num_tokens/piece=24.0485\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=122803 obj=8.92764 num_tokens=2953731 num_tokens/piece=24.0526\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=92099 obj=8.96338 num_tokens=3034116 num_tokens/piece=32.9441\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=92096 obj=8.95671 num_tokens=3034119 num_tokens/piece=32.9452\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=69070 obj=9.00286 num_tokens=3122977 num_tokens/piece=45.2147\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=69069 obj=8.99424 num_tokens=3122951 num_tokens/piece=45.2149\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=51800 obj=9.056 num_tokens=3219436 num_tokens/piece=62.1513\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=51800 obj=9.0464 num_tokens=3219397 num_tokens/piece=62.1505\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=38850 obj=9.12628 num_tokens=3322847 num_tokens/piece=85.5302\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=38850 obj=9.11215 num_tokens=3322895 num_tokens/piece=85.5314\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=29137 obj=9.21615 num_tokens=3435234 num_tokens/piece=117.899\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=29137 obj=9.19788 num_tokens=3435373 num_tokens/piece=117.904\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=21852 obj=9.33013 num_tokens=3557694 num_tokens/piece=162.809\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=21852 obj=9.30661 num_tokens=3557735 num_tokens/piece=162.81\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=16389 obj=9.46987 num_tokens=3690394 num_tokens/piece=225.175\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=16389 obj=9.43901 num_tokens=3690453 num_tokens/piece=225.179\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=12291 obj=9.64397 num_tokens=3838886 num_tokens/piece=312.333\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=12291 obj=9.60618 num_tokens=3839166 num_tokens/piece=312.356\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=0 size=11000 obj=9.68872 num_tokens=3897128 num_tokens/piece=354.284\n",
            "unigram_model_trainer.cc(580) LOG(INFO) EM sub_iter=1 size=11000 obj=9.67401 num_tokens=3897373 num_tokens/piece=354.307\n",
            "trainer_interface.cc(686) LOG(INFO) Saving model: target.model\n",
            "trainer_interface.cc(698) LOG(INFO) Saving vocabs: target.vocab\n",
            "Done, training a SentencepPiece model for the Target finished successfully!\n"
          ]
        }
      ],
      "source": [
        "# Train a SentencePiece model for subword tokenization\n",
        "!python3 MT-Preparation/subwording/1-train_unigram.py EUbookshop.en-nl.en-filtered.en EUbookshop.en-nl.nl-filtered.nl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vj4rUTgIptYV",
        "outputId": "46dcaccc-4854-4c77-9a68-f3e21fb690ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EUbookshop.en-nl.en\t\t EUbookshop.en-nl.nl\t\t  README\ttarget.model\n",
            "EUbookshop.en-nl.en-filtered.en  EUbookshop.en-nl.nl-filtered.nl  source.model\ttarget.vocab\n",
            "EUbookshop.en-nl.ids\t\t MT-Preparation\t\t\t  source.vocab\n"
          ]
        }
      ],
      "source": [
        "!ls\n",
        "!cd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAfGoheqs1AK",
        "outputId": "25edc150-333e-49d4-9414-4f08993f98de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['MT-Preparation/subwording/2-subword.py', 'source.model', 'target.model', 'EUbookshop.en-nl.en-filtered.en', 'EUbookshop.en-nl.nl-filtered.nl']\n",
            "source.model\n",
            "target.model\n",
            "EUbookshop.en-nl.en-filtered.en\n",
            "EUbookshop.en-nl.nl-filtered.nl\n",
            "Source Model: source.model\n",
            "Target Model: target.model\n",
            "Source Dataset: EUbookshop.en-nl.en-filtered.en\n",
            "Target Dataset: EUbookshop.en-nl.nl-filtered.nl\n",
            "Done subwording the source file! Output: EUbookshop.en-nl.en-filtered.en.subword\n",
            "Done subwording the target file! Output: EUbookshop.en-nl.nl-filtered.nl.subword\n"
          ]
        }
      ],
      "source": [
        "# Subword the dataset\n",
        "!python3 MT-Preparation/subwording/2-subword.py source.model target.model EUbookshop.en-nl.en-filtered.en EUbookshop.en-nl.nl-filtered.nl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tu5nXLxmtFdr",
        "outputId": "b2406827-cf46-44ff-8596-aa2c37237097"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That is why we are appealing to the governments' sense of responsibility.\n",
            "Sent to press in June 2003\n",
            "Monetary policy has to be conducted with market-based instruments and has to be 'efficient' in transmitting its impulses to the real economy.\n",
            "-----\n",
            "Daarom appelleren wij aan het verantwoordelijkheidsbesef van de regeringen.\n",
            "Manuscript beëindigd in mei 2003.\n",
            "Het personeel van de toezichthoudende instantie voor overheidssteun lijkt voldoende bekwaam.\n"
          ]
        }
      ],
      "source": [
        "# First 3 lines before subwording\n",
        "!tail -n 3 EUbookshop.en-nl.en-filtered.en && echo \"-----\" && tail -n 3 EUbookshop.en-nl.nl-filtered.nl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WOxmj6CE0NQ",
        "outputId": "5d14ee1f-cb56-4009-b831-5811aa2eebce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframe shape: (4670133, 2)\n",
            "--- Empty Cells Deleted --> Rows: 4670133\n",
            "--- Wrote Files\n",
            "Done!\n",
            "Output files\n",
            "EUbookshop.en-nl.nl-filtered.nl.subword.train\n",
            "EUbookshop.en-nl.en-filtered.en.subword.train\n",
            "EUbookshop.en-nl.nl-filtered.nl.subword.dev\n",
            "EUbookshop.en-nl.en-filtered.en.subword.dev\n",
            "EUbookshop.en-nl.nl-filtered.nl.subword.test\n",
            "EUbookshop.en-nl.en-filtered.en.subword.test\n"
          ]
        }
      ],
      "source": [
        "# Split the dataset into training set, development set, and test set\n",
        "# Development and test sets should be between 1000 and 5000 segments (here we chose 2000)\n",
        "!python3 MT-Preparation/train_dev_split/train_dev_test_split.py 2000 2000 EUbookshop.en-nl.nl-filtered.nl.subword EUbookshop.en-nl.en-filtered.en.subword\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJ5HusRJFKJT",
        "outputId": "4af24134-c220-4b18-a6cd-47e50aa05467"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      2000 EUbookshop.en-nl.en-filtered.en.subword.dev\n",
            "      2000 EUbookshop.en-nl.en-filtered.en.subword.test\n",
            "   4666133 EUbookshop.en-nl.en-filtered.en.subword.train\n",
            "      2000 EUbookshop.en-nl.nl-filtered.nl.subword.dev\n",
            "      2000 EUbookshop.en-nl.nl-filtered.nl.subword.test\n",
            "   4666133 EUbookshop.en-nl.nl-filtered.nl.subword.train\n",
            "   9340266 total\n"
          ]
        }
      ],
      "source": [
        "# Line count for the subworded train, dev, test datatest\n",
        "!wc -l *.subword.*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the first and last line from each dataset\n",
        "\n",
        "# -------------------------------------------\n",
        "# Change this cell to print your name\n",
        "!echo -e \"My name is: FirstName SecondName \\n\"\n",
        "# -------------------------------------------\n",
        "\n",
        "!echo \"---First line---\"\n",
        "!head -n 1 *.{train,dev,test}\n",
        "\n",
        "!echo -e \"\\n---Last line---\"\n",
        "!tail -n 1 *.{train,dev,test}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3aYYYg9jTh1",
        "outputId": "ca049f14-7e78-4d7e-d5c3-0303768566b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My name is: FirstName SecondName \n",
            "\n",
            "---First line---\n",
            "==> EUbookshop.en-nl.en-filtered.en.subword.train <==\n",
            "▁All ▁of ▁this ▁of ▁course ▁entail s ▁the ▁need ▁for ▁financial ▁resources , ▁and ▁we ▁can ▁but ▁agree ▁with ▁the ▁President ' s ▁words ▁this ▁morning ▁when ▁he ▁said ▁that ▁we ▁must ▁have ▁adequate , ▁stable ▁and ▁guaranteed ▁own ▁resources .\n",
            "\n",
            "==> EUbookshop.en-nl.nl-filtered.nl.subword.train <==\n",
            "▁De ▁landbouwers ▁in ▁mijn ▁kiesdistrict ▁in ▁Noord - Ierland ▁die ▁een ▁netto ▁inkomsten da ling ▁van ▁ 4 5 ▁% ▁in ▁ 1 9 8 5 ▁en ▁een ▁verdere ▁verlaging ▁ 1 9 8 6 ▁hebben ▁moeten ▁ver d uren , ▁maken ▁zich ▁met ▁recht ▁zorgen ▁over ▁het ▁kennelijk e ▁gebrek ▁aan ▁vastbesloten heid ▁van ▁de ▁zijde ▁van ▁de ▁Commissie ▁om ▁een ▁einde ▁te ▁maken ▁aan ▁de ▁prijzen discriminatie ▁die ▁nu ▁in ▁hun ▁na deel ▁uit val t .\n",
            "\n",
            "==> EUbookshop.en-nl.en-filtered.en.subword.dev <==\n",
            "▁The ▁interaction ▁of ▁people ▁of ▁different ▁national ities ▁in ▁initial ▁and ▁continuing ▁training ▁depends , ▁however , ▁not ▁only ▁on ▁linguistic , ▁technical , ▁method ological ▁and ▁social ▁competence , ▁but ▁also ▁on ▁inter cultural ▁education , ▁i . e . ▁the ▁ability ▁to ▁per ce ive ▁and ▁respect ▁the ▁peculiar ities ▁and ▁specific ▁features ▁of ▁other ▁culture s ▁and ▁national ities .\n",
            "\n",
            "==> EUbookshop.en-nl.nl-filtered.nl.subword.dev <==\n",
            "▁In ▁dit ▁verband ▁wijzen ▁wij ▁op ▁de ▁A ka de mie ▁für ▁F ü hr ung sp ä dag og ik ▁( beroep sbe geleid ende ▁opleiding ▁be ▁ drijf spe dag og iek ▁in ▁Land au ▁en ▁Du is burg ) ▁in ▁Duitsland , ▁het ▁A ar hu s ▁Te ch ni cal ▁College ▁in ▁Denemarken , ▁de ▁Lo cal ▁G over n ment ▁Tra in ing ▁Bo ard ▁in ▁Lu ton ▁in ▁ Engeland , ▁de ▁Pe dag o gische ▁Technische ▁Hoge ▁school ▁in ▁Eind ho ven ▁in ▁Nederland , ▁de ▁ Universit é ▁D au ph ine ▁in ▁Parijs , ▁enzovoort .\n",
            "\n",
            "==> EUbookshop.en-nl.en-filtered.en.subword.test <==\n",
            "▁The ▁funds ▁available ▁will ▁be ▁broken ▁down ▁internal ly ▁subject ▁to ▁the ▁following ▁restrictions :\n",
            "\n",
            "==> EUbookshop.en-nl.nl-filtered.nl.subword.test <==\n",
            "▁De ▁interne ▁verdeling ▁van ▁de ▁beschikbare ▁middelen ▁geschiedt ▁met ▁inachtneming ▁van ▁de ▁volgende ▁grenzen :\n",
            "\n",
            "---Last line---\n",
            "==> EUbookshop.en-nl.en-filtered.en.subword.train <==\n",
            "▁Monetary ▁policy ▁has ▁to ▁be ▁conducted ▁with ▁market - based ▁instruments ▁and ▁has ▁to ▁be ▁' efficient ' ▁in ▁transmit ting ▁its ▁im pulse s ▁to ▁the ▁real ▁economy .\n",
            "\n",
            "==> EUbookshop.en-nl.nl-filtered.nl.subword.train <==\n",
            "▁Het ▁personeel ▁van ▁de ▁ toezichthoudende ▁instantie ▁voor ▁overheidssteun ▁lijkt ▁voldoende ▁ bekwaam .\n",
            "\n",
            "==> EUbookshop.en-nl.en-filtered.en.subword.dev <==\n",
            "▁We ▁stress ▁that , ▁within ▁the ▁context ▁of ▁a ▁broadly based ▁strategy ▁aimed ▁at ▁improving ▁the ▁prospects ▁of ▁economic ▁development ▁and ▁based ▁on ▁sym metric al ▁rights ▁and ▁obligations ▁of ▁all ▁participants , ▁the ▁most ▁im ▁port ant ▁concern ▁should ▁be ▁to ▁enhance ▁the ▁con ▁v erg ence ▁of ▁economic ▁policies ▁towards ▁greater ▁stability .\n",
            "\n",
            "==> EUbookshop.en-nl.nl-filtered.nl.subword.dev <==\n",
            "▁Wij ▁beklemtonen ▁dat , ▁in ▁het ▁kader ▁van ▁een ▁strategie ▁op ▁brede ▁grondslag ▁die ▁gericht ▁is ▁op ▁een ▁verbetering ▁van ▁de ▁economische ▁ontwikkeling ▁en ▁gebaseerd ▁is ▁op ▁ s ym met rische ▁rechten ▁en ▁verplichtingen ▁van ▁alle ▁deelnemers , ▁in ▁de ▁eerste ▁plaats ▁dient ▁te ▁worden ▁gestreefd ▁naar ▁een ▁ver ▁sterk ing ▁van ▁de ▁convergentie ▁van ▁de ▁economische ▁politiek ▁naar ▁een ▁grotere ▁stabiliteit .\n",
            "\n",
            "==> EUbookshop.en-nl.en-filtered.en.subword.test <==\n",
            "▁The ▁conclusion ▁seems ▁to ▁be ▁that ▁most ▁of ▁the ▁C EC s ▁are ▁not ▁yet ▁effectively ▁competing ▁in ▁the ▁same ▁sections ▁of ▁the ▁market ▁with ▁even ▁the ▁southern ▁EU ▁Member ▁States , ▁given ▁the ▁large ▁differences ▁in ▁unit ▁values ▁between ▁the ▁exports ▁of ▁the ▁two ▁which ▁exist .\n",
            "\n",
            "==> EUbookshop.en-nl.nl-filtered.nl.subword.test <==\n",
            "▁ ME - landen ▁meer ▁gericht ▁zijn ▁op ▁het ▁lagere ▁prijs - ▁en ▁kwa ll teit s segment ▁van ▁de ▁markt ▁en ▁bijvoorbeeld ▁half ▁producten ▁voor ▁ as s em bla ge ▁naar ▁de ▁EU ▁export eren .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy your data to your Google Drive\n",
        "!cp -R /content/nmt/nmt/ /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "Uu0huGeDjVQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewVECMkRtaNl",
        "outputId": "f2900dce-dbb9-4d3d-c6b5-0cf5f9522939"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/nmt/\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIlmFweipN7s",
        "outputId": "15dc8266-3ecf-47bd-fe96-cf8435d329f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1LaNAl6bK3DlyjXhNqVJj5j2EAvh4Xn3o/nmt\n",
            "compute-bleu.py\n",
            "compute-bleu.py.1\n",
            "compute-bleu.py.2\n",
            "compute-bleu.py.3\n",
            "compute-bleu.py.4\n",
            "config.yaml\n",
            "en-nl.nl.test\n",
            "en-test.txt\n",
            "EUbookshop.en-nl.en\n",
            "EUbookshop.en-nl.en-filtered.en\n",
            "EUbookshop.en-nl.en-filtered.en.subword\n",
            "EUbookshop.en-nl.en-filtered.en.subword.dev\n",
            "EUbookshop.en-nl.en-filtered.en.subword.test\n",
            "EUbookshop.en-nl.en-filtered.en.subword.test.desubword\n",
            "EUbookshop.en-nl.en-filtered.en.subword.test.desubword.desubword\n",
            "EUbookshop.en-nl.en-filtered.en.subword.test.desubword.desubword.desubword\n",
            "EUbookshop.en-nl.en-filtered.en.subword.train\n",
            "EUbookshop.en-nl.ids\n",
            "EUbookshop.en-nl.nl\n",
            "EUbookshop.en-nl.nl-filtered.nl\n",
            "EUbookshop.en-nl.nl-filtered.nl.subword\n",
            "EUbookshop.en-nl.nl-filtered.nl.subword.dev\n",
            "EUbookshop.en-nl.nl-filtered.nl.subword.test\n",
            "EUbookshop.en-nl.nl-filtered.nl.subword.train\n",
            "EUbookshop.en-nl.nl.test\n",
            "models\n",
            "MT-Preparation\n",
            "nlen_ctranslate2\n",
            "README\n",
            "run\n",
            "source.model\n",
            "source.vocab\n",
            "target.model\n",
            "target.vocab\n",
            "train.log\n",
            "UN.nl.translated\n",
            "UN.nl.translated.desubword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the YAML configuration file\n",
        "# On a regular machine, you can create it manually or with nano\n",
        "# Note here we are using some smaller values because the dataset is small\n",
        "# For larger datasets, consider increasing: train_steps, valid_steps, warmup_steps, save_checkpoint_steps, keep_checkpoint\n",
        "\n",
        "config = '''# config.yaml\n",
        "\n",
        "## Where the samples will be written\n",
        "save_data: run\n",
        "\n",
        "\n",
        "# Training files\n",
        "data:\n",
        "    corpus_1:\n",
        "        path_src: /content/drive/MyDrive/nmt/EUbookshop.en-nl.en-filtered.en.subword.train\n",
        "        path_tgt: /content/drive/MyDrive/nmt/EUbookshop.en-nl.nl-filtered.nl.subword.train\n",
        "        transforms: [filtertoolong]\n",
        "    valid:\n",
        "        path_src: /content/drive/MyDrive/nmt/EUbookshop.en-nl.en-filtered.en.subword.dev\n",
        "        path_tgt: /content/drive/MyDrive/nmt/EUbookshop.en-nl.nl-filtered.nl.subword.dev\n",
        "        transforms: [filtertoolong]\n",
        "\n",
        "# Vocabulary files, generated by onmt_build_vocab\n",
        "src_vocab: run/source.vocab\n",
        "tgt_vocab: run/target.vocab\n",
        "\n",
        "# Vocabulary size - should be the same as in sentence piece\n",
        "src_vocab_size: 10000\n",
        "tgt_vocab_size: 10000\n",
        "\n",
        "# Filter out source/target longer than n if [filtertoolong] enabled\n",
        "src_seq_length: 150\n",
        "src_seq_length: 150\n",
        "\n",
        "# Tokenization options\n",
        "src_subword_model: source.model\n",
        "tgt_subword_model: target.model\n",
        "\n",
        "# Where to save the log file and the output models/checkpoints\n",
        "log_file: train.log\n",
        "save_model: models/model.fren\n",
        "\n",
        "# Stop training if it does not imporve after n validations\n",
        "early_stopping: 4\n",
        "\n",
        "# Default: 5000 - Save a model checkpoint for each n\n",
        "save_checkpoint_steps: 1000\n",
        "\n",
        "# To save space, limit checkpoints to last n\n",
        "#keep_checkpoint: 13\n",
        "\n",
        "seed: 3435\n",
        "\n",
        "# Default: 100000 - Train the model to max n steps\n",
        "# Increase to 200000 or more for large datasets\n",
        "# For fine-tuning, add up the required steps to the original steps\n",
        "train_steps: 50000\n",
        "\n",
        "# Default: 10000 - Run validation after n steps\n",
        "valid_steps: 5000\n",
        "\n",
        "# Default: 4000 - for large datasets, try up to 8000\n",
        "warmup_steps: 2500\n",
        "report_every: 2500\n",
        "\n",
        "# Number of GPUs, and IDs of GPUs\n",
        "world_size: 1\n",
        "gpu_ranks: [0]\n",
        "\n",
        "# Batching\n",
        "bucket_size: 262144\n",
        "num_workers: 0  # Default: 2, set to 0 when RAM out of memory\n",
        "batch_type: \"tokens\"\n",
        "batch_size: 4096   # Tokens per batch, change when CUDA out of memory\n",
        "valid_batch_size: 2048\n",
        "max_generator_batches: 2\n",
        "accum_count: [4]\n",
        "accum_steps: [0]\n",
        "\n",
        "# Optimization\n",
        "model_dtype: \"fp16\"\n",
        "optim: \"adam\"\n",
        "learning_rate: 2\n",
        "# warmup_steps: 8000\n",
        "decay_method: \"noam\"\n",
        "adam_beta2: 0.998\n",
        "max_grad_norm: 0\n",
        "label_smoothing: 0.1\n",
        "param_init: 0\n",
        "param_init_glorot: true\n",
        "normalization: \"tokens\"\n",
        "\n",
        "# Model\n",
        "encoder_type: transformer\n",
        "decoder_type: transformer\n",
        "position_encoding: true\n",
        "enc_layers: 6\n",
        "dec_layers: 6\n",
        "heads: 8\n",
        "hidden_size: 512\n",
        "word_vec_size: 512\n",
        "transformer_ff: 2048\n",
        "dropout_steps: [0]\n",
        "dropout: [0.1]\n",
        "attention_dropout: [0.1]\n",
        "'''\n",
        "\n",
        "with open(\"config.yaml\", \"w+\") as config_yaml:\n",
        "  config_yaml.write(config)"
      ],
      "metadata": {
        "id": "wR4L9vq3pR5m"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# [Optional] Check the content of the configuration file\n",
        "!cat config.yaml"
      ],
      "metadata": {
        "id": "8bXidEPCFwNS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30d0ed5b-4274-469e-cc61-2525d53349b4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# config.yaml\n",
            "\n",
            "## Where the samples will be written\n",
            "save_data: run\n",
            "\n",
            "\n",
            "# Training files\n",
            "data:\n",
            "    corpus_1:\n",
            "        path_src: /content/drive/MyDrive/nmt/EUbookshop.en-nl.en-filtered.en.subword.train\n",
            "        path_tgt: /content/drive/MyDrive/nmt/EUbookshop.en-nl.nl-filtered.nl.subword.train\n",
            "        transforms: [filtertoolong]\n",
            "    valid:\n",
            "        path_src: /content/drive/MyDrive/nmt/EUbookshop.en-nl.en-filtered.en.subword.dev\n",
            "        path_tgt: /content/drive/MyDrive/nmt/EUbookshop.en-nl.nl-filtered.nl.subword.dev\n",
            "        transforms: [filtertoolong]\n",
            "\n",
            "# Vocabulary files, generated by onmt_build_vocab\n",
            "src_vocab: run/source.vocab\n",
            "tgt_vocab: run/target.vocab\n",
            "\n",
            "# Vocabulary size - should be the same as in sentence piece\n",
            "src_vocab_size: 10000\n",
            "tgt_vocab_size: 10000\n",
            "\n",
            "# Filter out source/target longer than n if [filtertoolong] enabled\n",
            "src_seq_length: 150\n",
            "src_seq_length: 150\n",
            "\n",
            "# Tokenization options\n",
            "src_subword_model: source.model\n",
            "tgt_subword_model: target.model\n",
            "\n",
            "# Where to save the log file and the output models/checkpoints\n",
            "log_file: train.log\n",
            "save_model: models/model.fren\n",
            "\n",
            "# Stop training if it does not imporve after n validations\n",
            "early_stopping: 4\n",
            "\n",
            "# Default: 5000 - Save a model checkpoint for each n\n",
            "save_checkpoint_steps: 1000\n",
            "\n",
            "# To save space, limit checkpoints to last n\n",
            "#keep_checkpoint: 13\n",
            "\n",
            "seed: 3435\n",
            "\n",
            "# Default: 100000 - Train the model to max n steps\n",
            "# Increase to 200000 or more for large datasets\n",
            "# For fine-tuning, add up the required steps to the original steps\n",
            "train_steps: 50000\n",
            "\n",
            "# Default: 10000 - Run validation after n steps\n",
            "valid_steps: 5000\n",
            "\n",
            "# Default: 4000 - for large datasets, try up to 8000\n",
            "warmup_steps: 2500\n",
            "report_every: 2500\n",
            "\n",
            "# Number of GPUs, and IDs of GPUs\n",
            "world_size: 1\n",
            "gpu_ranks: [0]\n",
            "\n",
            "# Batching\n",
            "bucket_size: 262144\n",
            "num_workers: 0  # Default: 2, set to 0 when RAM out of memory\n",
            "batch_type: \"tokens\"\n",
            "batch_size: 4096   # Tokens per batch, change when CUDA out of memory\n",
            "valid_batch_size: 2048\n",
            "max_generator_batches: 2\n",
            "accum_count: [4]\n",
            "accum_steps: [0]\n",
            "\n",
            "# Optimization\n",
            "model_dtype: \"fp16\"\n",
            "optim: \"adam\"\n",
            "learning_rate: 2\n",
            "# warmup_steps: 8000\n",
            "decay_method: \"noam\"\n",
            "adam_beta2: 0.998\n",
            "max_grad_norm: 0\n",
            "label_smoothing: 0.1\n",
            "param_init: 0\n",
            "param_init_glorot: true\n",
            "normalization: \"tokens\"\n",
            "\n",
            "# Model\n",
            "encoder_type: transformer\n",
            "decoder_type: transformer\n",
            "position_encoding: true\n",
            "enc_layers: 6\n",
            "dec_layers: 6\n",
            "heads: 8\n",
            "hidden_size: 512\n",
            "word_vec_size: 512\n",
            "transformer_ff: 2048\n",
            "dropout_steps: [0]\n",
            "dropout: [0.1]\n",
            "attention_dropout: [0.1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the number of CPUs/cores on the machine\n",
        "!nproc --all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQVJw8BTpqu7",
        "outputId": "702e58f6-7744-4a09-97dc-a306f565d526"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Vocabulary\n",
        "\n",
        "# -config: path to your config.yaml file\n",
        "# -n_sample: use -1 to build vocabulary on all the segment in the training dataset\n",
        "# -num_threads: change it to match the number of CPUs to run it faster\n",
        "\n",
        "!onmt_build_vocab -config config.yaml -n_sample -1 -num_threads 2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gCPwGDipt4Q",
        "outputId": "7beb6c69-4731-467c-c3e7-34d6aa2fd177"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-23 01:01:37.283568: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-23 01:01:37.283622: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-23 01:01:37.283658: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-23 01:01:37.291698: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-23 01:01:38.663568: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-11-23 01:01:39.807723: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-23 01:01:39.808126: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-23 01:01:39.808279: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "Error in sys.excepthook:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 46, in getlines\n",
            "    return updatecache(filename, module_globals)\n",
            "  File \"/usr/lib/python3.10/linecache.py\", line 137, in updatecache\n",
            "    lines = fp.readlines()\n",
            "  File \"/usr/lib/python3.10/codecs.py\", line 319, in decode\n",
            "    def decode(self, input, final=False):\n",
            "KeyboardInterrupt\n",
            "\n",
            "Original exception was:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/onmt_build_vocab\", line 5, in <module>\n",
            "    from onmt.bin.build_vocab import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/onmt/__init__.py\", line 2, in <module>\n",
            "    import onmt.inputters\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/onmt/inputters/__init__.py\", line 8, in <module>\n",
            "    from onmt.inputters.text_corpus import ParallelCorpus, ParallelCorpusIterator\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/onmt/inputters/text_corpus.py\", line 5, in <module>\n",
            "    from onmt.transforms import TransformPipe\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/onmt/transforms/__init__.py\", line 65, in <module>\n",
            "    module = importlib.import_module(\"onmt.transforms.\" + file_name)\n",
            "  File \"/usr/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/onmt/transforms/terminology.py\", line 5, in <module>\n",
            "    import spacy\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/__init__.py\", line 16, in <module>\n",
            "    from .cli.info import info  # noqa: F401\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/__init__.py\", line 13, in <module>\n",
            "    from .debug_diff import debug_diff  # noqa: F401\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/debug_diff.py\", line 10, in <module>\n",
            "    from .init_config import Optimizations, init_config\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/init_config.py\", line 27, in <module>\n",
            "    RECOMMENDATIONS = srsly.read_yaml(ROOT / \"quickstart_training_recommendations.yml\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/srsly/_yaml_api.py\", line 76, in read_yaml\n",
            "    return yaml_loads(f)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/srsly/_yaml_api.py\", line 60, in yaml_loads\n",
            "    return yaml.load(data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/srsly/ruamel_yaml/main.py\", line 356, in load\n",
            "    return constructor.get_single_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/srsly/ruamel_yaml/constructor.py\", line 114, in get_single_data\n",
            "    node = self.composer.get_single_node()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/srsly/ruamel_yaml/composer.py\", line 78, in get_single_node\n",
            "    document = self.compose_document()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/srsly/ruamel_yaml/composer.py\", line 101, in compose_document\n",
            "    node = self.compose_node(None, None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/srsly/ruamel_yaml/composer.py\", line 143, in compose_node\n",
            "    node = self.compose_mapping_node(anchor)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/srsly/ruamel_yaml/composer.py\", line 223, in compose_mapping_node\n",
            "    item_value = self.compose_node(node, item_key)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/srsly/ruamel_yaml/composer.py\", line 143, in compose_node\n",
            "    node = self.compose_mapping_node(anchor)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/srsly/ruamel_yaml/composer.py\", line 223, in compose_mapping_node\n",
            "    item_value = self.compose_node(node, item_key)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/srsly/ruamel_yaml/composer.py\", line 143, in compose_node\n",
            "    node = self.compose_mapping_node(anchor)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/srsly/ruamel_yaml/composer.py\", line 216, in compose_mapping_node\n",
            "    while not self.parser.check_event(MappingEndEvent):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/srsly/ruamel_yaml/parser.py\", line 140, in check_event\n",
            "    self.current_event = self.state()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/srsly/ruamel_yaml/parser.py\", line 603, in parse_block_mapping_first_key\n",
            "    return self.parse_block_mapping_key()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/srsly/ruamel_yaml/parser.py\", line 612, in parse_block_mapping_key\n",
            "    return self.parse_block_node_or_indentless_sequence()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/srsly/ruamel_yaml/parser.py\", line 347, in parse_block_node_or_indentless_sequence\n",
            "    return self.parse_node(block=True, indentless_sequence=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/srsly/ruamel_yaml/parser.py\", line 438, in parse_node\n",
            "    event = ScalarEvent(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/srsly/ruamel_yaml/events.py\", line 125, in __init__\n",
            "    def __init__(\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the GPU is active\n",
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJG5-sC-pvFE",
        "outputId": "5a8361bf-ce3b-400f-fbf8-f4b9f2164d99"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: NVIDIA A100-SXM4-40GB (UUID: GPU-81a32a1a-93ee-84da-d6e1-43b0978fd660)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "\n",
        "gpu_memory = torch.cuda.mem_get_info(0)\n",
        "print(\"Free GPU memory:\", gpu_memory[0]/1024**2, \"out of:\", gpu_memory[1]/1024**2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLpD2wQbpve7",
        "outputId": "a803efc9-2bc7-4faa-8c89-d9aff15b81bb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "NVIDIA A100-SXM4-40GB\n",
            "Free GPU memory: 40096.5625 out of: 40513.5625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf drive/MyDrive/nmt/models/\n"
      ],
      "metadata": {
        "id": "NdXNaxWfrEzW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F93ob1NEw3dM",
        "outputId": "4c8ca227-c04e-400e-c6ef-02c53f6a294f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "compute-bleu.py\n",
            "compute-bleu.py.1\n",
            "compute-bleu.py.2\n",
            "compute-bleu.py.3\n",
            "compute-bleu.py.4\n",
            "config.yaml\n",
            "en-nl.nl.test\n",
            "en-test.txt\n",
            "EUbookshop.en-nl.en\n",
            "EUbookshop.en-nl.en-filtered.en\n",
            "EUbookshop.en-nl.en-filtered.en.subword\n",
            "EUbookshop.en-nl.en-filtered.en.subword.dev\n",
            "EUbookshop.en-nl.en-filtered.en.subword.test\n",
            "EUbookshop.en-nl.en-filtered.en.subword.test.desubword\n",
            "EUbookshop.en-nl.en-filtered.en.subword.test.desubword.desubword\n",
            "EUbookshop.en-nl.en-filtered.en.subword.test.desubword.desubword.desubword\n",
            "EUbookshop.en-nl.en-filtered.en.subword.train\n",
            "EUbookshop.en-nl.ids\n",
            "EUbookshop.en-nl.nl\n",
            "EUbookshop.en-nl.nl-filtered.nl\n",
            "EUbookshop.en-nl.nl-filtered.nl.subword\n",
            "EUbookshop.en-nl.nl-filtered.nl.subword.dev\n",
            "EUbookshop.en-nl.nl-filtered.nl.subword.test\n",
            "EUbookshop.en-nl.nl-filtered.nl.subword.train\n",
            "EUbookshop.en-nl.nl.test\n",
            "models\n",
            "MT-Preparation\n",
            "nlen_ctranslate2\n",
            "README\n",
            "run\n",
            "source.model\n",
            "source.vocab\n",
            "target.model\n",
            "target.vocab\n",
            "train.log\n",
            "UN.nl.translated\n",
            "UN.nl.translated.desubword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!dmesg -T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jNX7ZQPwJr_",
        "outputId": "c1fbb049-d46c-48f4-9d3b-8e8967ce25f4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mLinux version 5.15.120+ (builder@ed0d1b4285f6) (Chromium OS 15.0_pre458507_p20220602-r18 clang version 15.0.0 (/var/tmp/portage/sys-devel/llvm-15.0_pre458507_p20220602-r18/work/llvm-15.0_pre458507_p20220602/clang a58d0af058038595c93de961b725f86997cf8d4a), LLD 15.0.0) #1 SMP Wed Aug 30 11:19:59 UTC 2023\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mCommand line\u001b[0m: BOOT_IMAGE=/syslinux/vmlinuz.A init=/usr/lib/systemd/systemd boot=local rootwait ro noresume loglevel=7 console=tty1 console=ttyS0 security=apparmor virtio_net.napi_tx=1 nmi_watchdog=0 csm.disabled=1 loadpin.exclude=kernel-module,firmware modules-load=loadpin_trigger firmware_class.path=/var/lib/nvidia/firmware module.sig_enforce=0 amd_iommu=off dm_verity.error_behavior=3 dm_verity.max_bios=-1 dm_verity.dev_wait=1 i915.modeset=1 cros_efi loadpin.enabled=0 root=/dev/dm-0 \"dm-mod.create=vroot,,,ro,0 4077568 verity 0 PARTUUID=78923FB4-2EC6-1847-A812-FBB8696295C7 PARTUUID=78923FB4-2EC6-1847-A812-FBB8696295C7 4096 4096 509696 509696 sha256 9d70a90b36d1aa6f57e10594cc020660b099b4150889f25040ff8ab63ea5797b 2db0e224f6697d716db7c21abfe32855ebed6042cb682a566dee613a8ef0e77a\" mitigations=off retbleed=off psi=1\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mx86/fpu\u001b[0m: Supporting XSAVE feature 0x001: 'x87 floating point registers'\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mx86/fpu\u001b[0m: Supporting XSAVE feature 0x002: 'SSE registers'\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mx86/fpu\u001b[0m: Supporting XSAVE feature 0x004: 'AVX registers'\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mx86/fpu\u001b[0m: Supporting XSAVE feature 0x008: 'MPX bounds registers'\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mx86/fpu\u001b[0m: Supporting XSAVE feature 0x010: 'MPX CSR'\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mx86/fpu\u001b[0m: Supporting XSAVE feature 0x020: 'AVX-512 opmask'\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mx86/fpu\u001b[0m: Supporting XSAVE feature 0x040: 'AVX-512 Hi256'\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mx86/fpu\u001b[0m: Supporting XSAVE feature 0x080: 'AVX-512 ZMM_Hi256'\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mx86/fpu\u001b[0m: xstate_offset[2]:  576, xstate_sizes[2]:  256\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mx86/fpu\u001b[0m: xstate_offset[3]:  832, xstate_sizes[3]:   64\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mx86/fpu\u001b[0m: xstate_offset[4]:  896, xstate_sizes[4]:   64\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mx86/fpu\u001b[0m: xstate_offset[5]:  960, xstate_sizes[5]:   64\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mx86/fpu\u001b[0m: xstate_offset[6]: 1024, xstate_sizes[6]:  512\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mx86/fpu\u001b[0m: xstate_offset[7]: 1536, xstate_sizes[7]: 1024\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mx86/fpu\u001b[0m: Enabled xstate features 0xff, context size is 2560 bytes, using 'compacted' format.\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33msignal\u001b[0m: max sigframe size: 3632\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mBIOS-provided physical RAM map:\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mBIOS-e820\u001b[0m: [mem 0x0000000000000000-0x0000000000000fff] reserved\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mBIOS-e820\u001b[0m: [mem 0x0000000000001000-0x0000000000054fff] usable\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mBIOS-e820\u001b[0m: [mem 0x0000000000055000-0x000000000005ffff] reserved\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mBIOS-e820\u001b[0m: [mem 0x0000000000060000-0x0000000000097fff] usable\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mBIOS-e820\u001b[0m: [mem 0x0000000000098000-0x000000000009ffff] reserved\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mBIOS-e820\u001b[0m: [mem 0x0000000000100000-0x00000000bf8ecfff] usable\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mBIOS-e820\u001b[0m: [mem 0x00000000bf8ed000-0x00000000bfb6cfff] reserved\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mBIOS-e820\u001b[0m: [mem 0x00000000bfb6d000-0x00000000bfb7efff] ACPI data\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mBIOS-e820\u001b[0m: [mem 0x00000000bfb7f000-0x00000000bfbfefff] ACPI NVS\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mBIOS-e820\u001b[0m: [mem 0x00000000bfbff000-0x00000000bffdffff] usable\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mBIOS-e820\u001b[0m: [mem 0x00000000bffe0000-0x00000000bfffffff] reserved\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mBIOS-e820\u001b[0m: [mem 0x0000000100000000-0x000000037fffffff] usable\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mNX (Execute Disable) protection\u001b[0m: active\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mefi\u001b[0m: EFI v2.70 by EDK II\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mefi\u001b[0m: TPMFinalLog=0xbfbf7000 ACPI=0xbfb7e000 ACPI 2.0=0xbfb7e014 SMBIOS=0xbf9ca000 MEMATTR=0xbe352018 MOKvar=0xbf9c8000 RNG=0xbfb73018 TPMEventLog=0xbe299018 \n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mSMBIOS 2.4 present.\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mDMI\u001b[0m: Google Google Compute Engine/Google Compute Engine, BIOS Google 10/09/2023\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mHypervisor detected\u001b[0m: KVM\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mkvm-clock\u001b[0m: Using msrs 4b564d01 and 4b564d00\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mkvm-clock\u001b[0m: cpu 0, msr 2a5000001, primary cpu clock\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mkvm-clock\u001b[0m: using sched offset of 6932919302 cycles\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mclocksource\u001b[0m: kvm-clock: mask: 0xffffffffffffffff max_cycles: 0x1cd42e4dffb, max_idle_ns: 881590591483 ns\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mtsc\u001b[0m: Detected 2000.166 MHz processor\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33me820\u001b[0m: update [mem 0x00000000-0x00000fff] usable ==> reserved\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33me820\u001b[0m: remove [mem 0x000a0000-0x000fffff] usable\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mlast_pfn = 0x380000 max_arch_pfn = 0x400000000\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mx86/PAT\u001b[0m: Configuration [0-7]: WB  WC  UC- UC  WB  WP  UC- WT  \n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mlast_pfn = 0xbffe0 max_arch_pfn = 0x400000000\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mKernel/User page tables isolation\u001b[0m: disabled on command line.\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mUsing GB pages for direct mapping\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mSecure boot disabled\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: Early table checksum verification disabled\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: RSDP 0x00000000BFB7E014 000024 (v02 Google)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: XSDT 0x00000000BFB7D0E8 00005C (v01 Google GOOGFACP 00000001      01000013)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: FACP 0x00000000BFB78000 0000F4 (v02 Google GOOGFACP 00000001 GOOG 00000001)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: DSDT 0x00000000BFB79000 001A64 (v01 Google GOOGDSDT 00000001 GOOG 00000001)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: FACS 0x00000000BFBF2000 000040\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: SSDT 0x00000000BFB7C000 000316 (v02 GOOGLE Tpm2Tabl 00001000 INTL 20211217)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: TPM2 0x00000000BFB7B000 000034 (v04 GOOGLE          00000001 GOOG 00000001)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: SRAT 0x00000000BFB77000 0000C8 (v03 Google GOOGSRAT 00000001 GOOG 00000001)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: APIC 0x00000000BFB76000 000076 (v05 Google GOOGAPIC 00000001 GOOG 00000001)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: SSDT 0x00000000BFB75000 000980 (v01 Google GOOGSSDT 00000001 GOOG 00000001)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: WAET 0x00000000BFB74000 000028 (v01 Google GOOGWAET 00000001 GOOG 00000001)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: Reserving FACP table memory at [mem 0xbfb78000-0xbfb780f3]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: Reserving DSDT table memory at [mem 0xbfb79000-0xbfb7aa63]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: Reserving FACS table memory at [mem 0xbfbf2000-0xbfbf203f]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: Reserving SSDT table memory at [mem 0xbfb7c000-0xbfb7c315]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: Reserving TPM2 table memory at [mem 0xbfb7b000-0xbfb7b033]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: Reserving SRAT table memory at [mem 0xbfb77000-0xbfb770c7]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: Reserving APIC table memory at [mem 0xbfb76000-0xbfb76075]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: Reserving SSDT table memory at [mem 0xbfb75000-0xbfb7597f]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: Reserving WAET table memory at [mem 0xbfb74000-0xbfb74027]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mSRAT\u001b[0m: PXM 0 -> APIC 0x00 -> Node 0\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mSRAT\u001b[0m: PXM 0 -> APIC 0x01 -> Node 0\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: SRAT: Node 0 PXM 0 [mem 0x00000000-0x0009ffff]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: SRAT: Node 0 PXM 0 [mem 0x00100000-0xbfffffff]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: SRAT: Node 0 PXM 0 [mem 0x100000000-0x37fffffff]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mNUMA\u001b[0m: Node 0 [mem 0x00000000-0x0009ffff] + [mem 0x00100000-0xbfffffff] -> [mem 0x00000000-0xbfffffff]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mNUMA\u001b[0m: Node 0 [mem 0x00000000-0xbfffffff] + [mem 0x100000000-0x37fffffff] -> [mem 0x00000000-0x37fffffff]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mNODE_DATA(0) allocated [mem 0x37fffb000-0x37fffffff]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mZone ranges:\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m  DMA      [mem 0x0000000000001000-0x0000000000ffffff]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m  DMA32    [mem 0x0000000001000000-0x00000000ffffffff]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m  Normal   [mem 0x0000000100000000-0x000000037fffffff]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m  Device   empty\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mMovable zone start for each node\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mEarly memory node ranges\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33m  node   0\u001b[0m: [mem 0x0000000000001000-0x0000000000054fff]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33m  node   0\u001b[0m: [mem 0x0000000000060000-0x0000000000097fff]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33m  node   0\u001b[0m: [mem 0x0000000000100000-0x00000000bf8ecfff]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33m  node   0\u001b[0m: [mem 0x00000000bfbff000-0x00000000bffdffff]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33m  node   0\u001b[0m: [mem 0x0000000100000000-0x000000037fffffff]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mInitmem setup node 0 [mem 0x0000000000001000-0x000000037fffffff]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mOn node 0, zone DMA\u001b[0m: 1 pages in unavailable ranges\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mOn node 0, zone DMA\u001b[0m: 11 pages in unavailable ranges\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mOn node 0, zone DMA\u001b[0m: 104 pages in unavailable ranges\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mOn node 0, zone DMA32\u001b[0m: 786 pages in unavailable ranges\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mOn node 0, zone Normal\u001b[0m: 32 pages in unavailable ranges\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: LAPIC_NMI (acpi_id[0xff] dfl dfl lint[0x1])\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mIOAPIC[0]\u001b[0m: apic_id 0, version 17, address 0xfec00000, GSI 0-23\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: INT_SRC_OVR (bus 0 bus_irq 5 global_irq 5 high level)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: INT_SRC_OVR (bus 0 bus_irq 9 global_irq 9 high level)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: INT_SRC_OVR (bus 0 bus_irq 10 global_irq 10 high level)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: INT_SRC_OVR (bus 0 bus_irq 11 global_irq 11 high level)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: Using ACPI (MADT) for SMP configuration information\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33msmpboot\u001b[0m: Allowing 2 CPUs, 0 hotplug CPUs\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m[mem 0xc0000000-0xffffffff] available for PCI devices\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mBooting paravirtualized kernel on KVM\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mclocksource\u001b[0m: refined-jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1910969940391419 ns\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33msetup_percpu\u001b[0m: NR_CPUS:512 nr_cpumask_bits:512 nr_cpu_ids:2 nr_node_ids:1\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpercpu\u001b[0m: Embedded 60 pages/cpu s208896 r8192 d28672 u1048576\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpcpu-alloc\u001b[0m: s208896 r8192 d28672 u1048576 alloc=1*2097152\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpcpu-alloc\u001b[0m: [0] 0 1 \n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mkvm-guest\u001b[0m: PV spinlocks enabled\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mPV qspinlock hash table entries\u001b[0m: 256 (order: 0, 4096 bytes, linear)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mBuilt 1 zonelists, mobility grouping on.  Total pages\u001b[0m: 3350520\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mPolicy zone\u001b[0m: Normal\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mKernel command line\u001b[0m: BOOT_IMAGE=/syslinux/vmlinuz.A init=/usr/lib/systemd/systemd boot=local rootwait ro noresume loglevel=7 console=tty1 console=ttyS0 security=apparmor virtio_net.napi_tx=1 nmi_watchdog=0 csm.disabled=1 loadpin.exclude=kernel-module,firmware modules-load=loadpin_trigger firmware_class.path=/var/lib/nvidia/firmware module.sig_enforce=0 amd_iommu=off dm_verity.error_behavior=3 dm_verity.max_bios=-1 dm_verity.dev_wait=1 i915.modeset=1 cros_efi loadpin.enabled=0 root=/dev/dm-0 \"dm-mod.create=vroot,,,ro,0 4077568 verity 0 PARTUUID=78923FB4-2EC6-1847-A812-FBB8696295C7 PARTUUID=78923FB4-2EC6-1847-A812-FBB8696295C7 4096 4096 509696 509696 sha256 9d70a90b36d1aa6f57e10594cc020660b099b4150889f25040ff8ab63ea5797b 2db0e224f6697d716db7c21abfe32855ebed6042cb682a566dee613a8ef0e77a\" mitigations=off retbleed=off psi=1\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mUnknown kernel command line parameters \"noresume cros_efi BOOT_IMAGE=/syslinux/vmlinuz.A boot=local modules-load=loadpin_trigger\", will be passed to user space.\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mDentry cache hash table entries\u001b[0m: 2097152 (order: 12, 16777216 bytes, linear)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mInode-cache hash table entries\u001b[0m: 1048576 (order: 11, 8388608 bytes, linear)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mmem auto-init\u001b[0m: stack:all(zero), heap alloc:off, heap free:off\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mMemory\u001b[0m: 13244848K/13627752K available (14348K kernel code, 2466K rwdata, 6068K rodata, 2156K init, 4668K bss, 382644K reserved, 0K cma-reserved)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mSLUB\u001b[0m: HWalign=64, Order=0-3, MinObjects=0, CPUs=2, Nodes=1\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mftrace\u001b[0m: allocating 40331 entries in 158 pages\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mftrace\u001b[0m: allocated 158 pages with 5 groups\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mrcu\u001b[0m: Hierarchical RCU implementation.\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mrcu\u001b[0m: \tRCU restricting CPUs from NR_CPUS=512 to nr_cpu_ids=2.\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\tRude variant of Tasks RCU enabled.\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\tTracing variant of Tasks RCU enabled.\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mrcu\u001b[0m: RCU calculated value of scheduler-enlistment delay is 100 jiffies.\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mrcu\u001b[0m: Adjusting geometry for rcu_fanout_leaf=16, nr_cpu_ids=2\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mNR_IRQS\u001b[0m: 33024, nr_irqs: 440, preallocated irqs: 16\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mrandom\u001b[0m: crng init done\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mConsole\u001b[0m: colour dummy device 80x25\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mprintk\u001b[0m: console [tty1] enabled\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mprintk\u001b[0m: console [ttyS0] enabled\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: Core revision 20210730\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mAPIC\u001b[0m: Switch to symmetric I/O mode setup\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mx2apic enabled\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mSwitched APIC routing to physical x2apic.\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33m..TIMER\u001b[0m: vector=0x30 apic1=0 pin1=0 apic2=-1 pin2=-1\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mclocksource\u001b[0m: tsc-early: mask: 0xffffffffffffffff max_cycles: 0x1cd4caf5f8f, max_idle_ns: 440795236170 ns\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mCalibrating delay loop (skipped) preset value.. 4000.33 BogoMIPS (lpj=2000166)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpid_max\u001b[0m: default: 32768 minimum: 301\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mLSM\u001b[0m: Security Framework initializing\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mYama\u001b[0m: becoming mindful.\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: ready to pin (currently enforcing)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: excluding: kernel-module\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: excluding: firmware\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mAppArmor\u001b[0m: AppArmor initialized\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mLSM support for eBPF active\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mMount-cache hash table entries\u001b[0m: 32768 (order: 6, 262144 bytes, linear)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mMountpoint-cache hash table entries\u001b[0m: 32768 (order: 6, 262144 bytes, linear)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mLast level iTLB entries\u001b[0m: 4KB 64, 2MB 8, 4MB 8\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mLast level dTLB entries\u001b[0m: 4KB 64, 2MB 0, 4MB 0, 1GB 4\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mSpectre V2 \u001b[0m: User space: Vulnerable\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mSpeculative Store Bypass\u001b[0m: Vulnerable\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mFreeing SMP alternatives memory\u001b[0m: 48K\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33msmpboot\u001b[0m: CPU0: Intel(R) Xeon(R) CPU @ 2.00GHz (family: 0x6, model: 0x55, stepping: 0x3)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mPerformance Events\u001b[0m: unsupported p6 CPU model 85 no PMU driver, software events only.\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mrcu\u001b[0m: Hierarchical SRCU implementation.\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mNMI watchdog\u001b[0m: Perf NMI watchdog permanently disabled\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33msmp\u001b[0m: Bringing up secondary CPUs ...\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mx86\u001b[0m: Booting SMP configuration:\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33m.... node  #0, CPUs\u001b[0m:      #1\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mkvm-clock\u001b[0m: cpu 1, msr 2a5000041, secondary cpu clock\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33msmp\u001b[0m: Brought up 1 node, 2 CPUs\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33msmpboot\u001b[0m: Max logical packages: 1\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33msmpboot\u001b[0m: Total of 2 processors activated (8000.66 BogoMIPS)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mdevtmpfs\u001b[0m: initialized\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mx86/mm\u001b[0m: Memory block size: 128MB\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: PM: Registering ACPI NVS region [mem 0xbfb7f000-0xbfbfefff] (524288 bytes)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mclocksource\u001b[0m: jiffies: mask: 0xffffffff max_cycles: 0xffffffff, max_idle_ns: 1911260446275000 ns\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mfutex hash table entries\u001b[0m: 512 (order: 3, 32768 bytes, linear)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mPM\u001b[0m: RTC time: 07:08:18, date: 2023-11-23\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mNET\u001b[0m: Registered PF_NETLINK/PF_ROUTE protocol family\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mDMA\u001b[0m: preallocated 2048 KiB GFP_KERNEL pool for atomic allocations\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mDMA\u001b[0m: preallocated 2048 KiB GFP_KERNEL|GFP_DMA pool for atomic allocations\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mDMA\u001b[0m: preallocated 2048 KiB GFP_KERNEL|GFP_DMA32 pool for atomic allocations\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33maudit\u001b[0m: initializing netlink subsys (disabled)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33maudit\u001b[0m: type=2000 audit(1700723297.883:1): state=initialized audit_enabled=0 res=1\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mthermal_sys\u001b[0m: Registered thermal governor 'step_wise'\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mthermal_sys\u001b[0m: Registered thermal governor 'user_space'\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mcpuidle\u001b[0m: using governor ladder\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mcpuidle\u001b[0m: using governor menu\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: bus type PCI registered\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33macpiphp\u001b[0m: ACPI Hot Plug PCI Controller Driver version: 0.5\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mPCI\u001b[0m: Using configuration type 1 for base access\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mkprobes\u001b[0m: kprobe jump-optimization is enabled. All kprobes are optimized if possible.\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mHugeTLB registered 1.00 GiB page size, pre-allocated 0 pages\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mHugeTLB registered 2.00 MiB page size, pre-allocated 0 pages\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: Added _OSI(Module Device)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: Added _OSI(Processor Device)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: Added _OSI(3.0 _SCP Extensions)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: Added _OSI(Processor Aggregator Device)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: Added _OSI(Linux-Dell-Video)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: Added _OSI(Linux-Lenovo-NV-HDMI-Audio)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: Added _OSI(Linux-HPI-Hybrid-Graphics)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: 3 ACPI AML tables successfully acquired and loaded\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: Interpreter enabled\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: PM: (supports S0 S3 S5)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: Using IOAPIC for interrupt routing\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mPCI\u001b[0m: Using host bridge windows from ACPI; if necessary, use \"pci=nocrs\" and report a bug\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: Enabled 16 GPEs in block 00 to 0F\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: PCI Root Bridge [PCI0] (domain 0000 [bus 00-ff])\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33macpi PNP0A03:00\u001b[0m: _OSC: OS supports [ASPM ClockPM Segments MSI HPX-Type3]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33macpi PNP0A03:00\u001b[0m\u001b[1m: fail to add MMCONFIG information, can't access extended PCI configuration space under this bridge.\u001b[0m\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mPCI host bridge to bus 0000:00\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci_bus 0000:00\u001b[0m: root bus resource [io  0x0000-0x0cf7 window]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci_bus 0000:00\u001b[0m: root bus resource [io  0x0d00-0xffff window]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci_bus 0000:00\u001b[0m: root bus resource [mem 0x000a0000-0x000bffff window]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci_bus 0000:00\u001b[0m: root bus resource [mem 0xc0000000-0xc1ffffff window]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci_bus 0000:00\u001b[0m: root bus resource [mem 0xc2040000-0xc4ffffff window]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci_bus 0000:00\u001b[0m: root bus resource [mem 0xc5040000-0xc50fffff window]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci_bus 0000:00\u001b[0m: root bus resource [mem 0xc5140000-0xeaffffff window]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci_bus 0000:00\u001b[0m: root bus resource [mem 0xeb040000-0xedffffff window]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci_bus 0000:00\u001b[0m: root bus resource [mem 0xee040000-0xee0fffff window]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci_bus 0000:00\u001b[0m: root bus resource [mem 0xee140000-0xfebfefff window]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci_bus 0000:00\u001b[0m: root bus resource [mem 0x380000000-0x2037fffffff window]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci_bus 0000:00\u001b[0m: root bus resource [bus 00-ff]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci 0000:00:00.0\u001b[0m: [8086:1237] type 00 class 0x060000\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci 0000:00:01.0\u001b[0m: [8086:7110] type 00 class 0x060100\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci 0000:00:01.3\u001b[0m: [8086:7113] type 00 class 0x068000\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci 0000:00:01.3\u001b[0m: quirk: [io  0xb000-0xb03f] claimed by PIIX4 ACPI\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci 0000:00:03.0\u001b[0m: [1af4:1004] type 00 class 0x000000\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci 0000:00:03.0\u001b[0m: reg 0x10: [io  0xc040-0xc07f]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci 0000:00:03.0\u001b[0m: reg 0x14: [mem 0xc1001000-0xc100107f]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci 0000:00:04.0\u001b[0m: [10de:1db1] type 00 class 0x030200\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci 0000:00:04.0\u001b[0m: reg 0x10: [mem 0xc0000000-0xc0ffffff]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci 0000:00:04.0\u001b[0m: reg 0x14: [mem 0x400000000-0x7ffffffff 64bit pref]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci 0000:00:04.0\u001b[0m: reg 0x1c: [mem 0x800000000-0x801ffffff 64bit pref]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci 0000:00:04.0\u001b[0m: Enabling HDA controller\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci 0000:00:05.0\u001b[0m: [1af4:1000] type 00 class 0x020000\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci 0000:00:05.0\u001b[0m: reg 0x10: [io  0xc000-0xc03f]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci 0000:00:05.0\u001b[0m: reg 0x14: [mem 0xc1000000-0xc100007f]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci 0000:00:06.0\u001b[0m: [1af4:1005] type 00 class 0x00ff00\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci 0000:00:06.0\u001b[0m: reg 0x10: [io  0xc080-0xc09f]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci 0000:00:06.0\u001b[0m: reg 0x14: [mem 0xc1002000-0xc100203f]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: PCI: Interrupt link LNKA configured for IRQ 10\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: PCI: Interrupt link LNKB configured for IRQ 10\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: PCI: Interrupt link LNKC configured for IRQ 11\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: PCI: Interrupt link LNKD configured for IRQ 11\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: PCI: Interrupt link LNKS configured for IRQ 9\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33miommu\u001b[0m: Default domain type: Translated \n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33miommu\u001b[0m: DMA domain TLB invalidation policy: lazy mode \n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mSCSI subsystem initialized\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mlibata version 3.00 loaded.\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpps_core\u001b[0m: LinuxPPS API ver. 1 registered\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpps_core\u001b[0m: Software ver. 5.3.6 - Copyright 2005-2007 Rodolfo Giometti <giometti@linux.it>\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mPTP clock support registered\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mRegistered efivars operations\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mPCI\u001b[0m: Using ACPI for IRQ routing\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mPCI\u001b[0m: pci_cache_line_size set to 64 bytes\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33me820\u001b[0m: reserve RAM buffer [mem 0x00055000-0x0005ffff]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33me820\u001b[0m: reserve RAM buffer [mem 0x00098000-0x0009ffff]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33me820\u001b[0m: reserve RAM buffer [mem 0xbf8ed000-0xbfffffff]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33me820\u001b[0m: reserve RAM buffer [mem 0xbffe0000-0xbfffffff]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mclocksource\u001b[0m: Switched to clocksource kvm-clock\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mVFS\u001b[0m: Disk quotas dquot_6.6.0\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mVFS\u001b[0m: Dquot-cache hash table entries: 512 (order 0, 4096 bytes)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mAppArmor\u001b[0m: AppArmor Filesystem Enabled\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpnp\u001b[0m: PnP ACPI init\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpnp\u001b[0m: PnP ACPI: found 7 devices\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mNET\u001b[0m: Registered PF_INET protocol family\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mIP idents hash table entries\u001b[0m: 262144 (order: 9, 2097152 bytes, linear)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mtcp_listen_portaddr_hash hash table entries\u001b[0m: 8192 (order: 5, 131072 bytes, linear)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mTable-perturb hash table entries\u001b[0m: 65536 (order: 6, 262144 bytes, linear)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mTCP established hash table entries\u001b[0m: 131072 (order: 8, 1048576 bytes, linear)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mTCP bind hash table entries\u001b[0m: 65536 (order: 8, 1048576 bytes, linear)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mTCP\u001b[0m: Hash tables configured (established 131072 bind 65536)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mUDP hash table entries\u001b[0m: 8192 (order: 6, 262144 bytes, linear)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mUDP-Lite hash table entries\u001b[0m: 8192 (order: 6, 262144 bytes, linear)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mNET\u001b[0m: Registered PF_UNIX/PF_LOCAL protocol family\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mNET\u001b[0m: Registered PF_XDP protocol family\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci_bus 0000:00\u001b[0m: resource 4 [io  0x0000-0x0cf7 window]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci_bus 0000:00\u001b[0m: resource 5 [io  0x0d00-0xffff window]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci_bus 0000:00\u001b[0m: resource 6 [mem 0x000a0000-0x000bffff window]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci_bus 0000:00\u001b[0m: resource 7 [mem 0xc0000000-0xc1ffffff window]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci_bus 0000:00\u001b[0m: resource 8 [mem 0xc2040000-0xc4ffffff window]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci_bus 0000:00\u001b[0m: resource 9 [mem 0xc5040000-0xc50fffff window]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci_bus 0000:00\u001b[0m: resource 10 [mem 0xc5140000-0xeaffffff window]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci_bus 0000:00\u001b[0m: resource 11 [mem 0xeb040000-0xedffffff window]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci_bus 0000:00\u001b[0m: resource 12 [mem 0xee040000-0xee0fffff window]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci_bus 0000:00\u001b[0m: resource 13 [mem 0xee140000-0xfebfefff window]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci_bus 0000:00\u001b[0m: resource 14 [mem 0x380000000-0x2037fffffff window]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mpci 0000:00:00.0\u001b[0m: Limiting direct PCI/PCI transfers\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mPCI\u001b[0m: CLS 0 bytes, default 64\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mPCI-DMA\u001b[0m: Using software bounce buffering for IO (SWIOTLB)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33msoftware IO TLB\u001b[0m: mapped [mem 0x00000000b7ff7000-0x00000000bbff7000] (64MB)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mRAPL PMU\u001b[0m: API unit is 2^-32 Joules, 0 fixed counters, 10737418240 ms ovfl timer\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mclocksource\u001b[0m: tsc: mask: 0xffffffffffffffff max_cycles: 0x1cd4caf5f8f, max_idle_ns: 440795236170 ns\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mclocksource\u001b[0m: Switched to clocksource tsc\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mInitialise system trusted keyrings\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mKey type blacklist registered\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mworkingset\u001b[0m: timestamp_bits=40 max_order=22 bucket_order=0\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mSGI XFS with ACLs, security attributes, quota, no debug enabled\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33m9p\u001b[0m: Installing v9fs 9p2000 file system support\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mintegrity\u001b[0m: Platform Keyring initialized\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mNET\u001b[0m: Registered PF_ALG protocol family\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mxor\u001b[0m: automatically using best checksumming function   avx       \n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mKey type asymmetric registered\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mAsymmetric key parser 'x509' registered\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mBlock layer SCSI generic (bsg) driver version 0.4 loaded (major 248)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mio scheduler mq-deadline registered\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33minput\u001b[0m: Power Button as /devices/LNXSYSTM:00/LNXPWRBN:00/input/input0\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: button: Power Button [PWRF]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33minput\u001b[0m: Sleep Button as /devices/LNXSYSTM:00/LNXSLPBN:00/input/input1\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: button: Sleep Button [SLPF]\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: \\_SB_.LNKC: Enabled at IRQ 11\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mvirtio-pci 0000:00:03.0\u001b[0m: virtio_pci: leaving for legacy driver\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: \\_SB_.LNKA: Enabled at IRQ 10\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mvirtio-pci 0000:00:05.0\u001b[0m: virtio_pci: leaving for legacy driver\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mACPI\u001b[0m: \\_SB_.LNKB: Enabled at IRQ 10\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mvirtio-pci 0000:00:06.0\u001b[0m: virtio_pci: leaving for legacy driver\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mSerial\u001b[0m: 8250/16550 driver, 4 ports, IRQ sharing disabled\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33m00:03\u001b[0m: ttyS0 at I/O 0x3f8 (irq = 4, base_baud = 115200) is a 16550A\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33m00:04\u001b[0m: ttyS1 at I/O 0x2f8 (irq = 3, base_baud = 115200) is a 16550A\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33m00:05\u001b[0m: ttyS2 at I/O 0x3e8 (irq = 6, base_baud = 115200) is a 16550A\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33m00:06\u001b[0m: ttyS3 at I/O 0x2e8 (irq = 7, base_baud = 115200) is a 16550A\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mNon-volatile memory driver v1.3\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mtpm_tis MSFT0101:00\u001b[0m: 2.0 TPM (device-id 0x9009, rev-id 0)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mloop\u001b[0m: module loaded\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mGuest personality initialized and is inactive\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mVMCI host device registered (name=vmci, major=10, minor=127)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mInitialized host personality\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mscsi host0\u001b[0m: Virtio SCSI HBA\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mscsi 0:0:1:0\u001b[0m: Direct-Access     Google   PersistentDisk   1    PQ: 0 ANSI: 6\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mVMware PVSCSI driver - version 1.0.7.0-k\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mhv_vmbus\u001b[0m: registering driver hv_storvsc\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33msd 0:0:1:0\u001b[0m: [sda] 115343360 512-byte logical blocks: (59.1 GB/55.0 GiB)\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33msd 0:0:1:0\u001b[0m: [sda] 4096-byte physical blocks\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33msd 0:0:1:0\u001b[0m: [sda] Write Protect is off\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33msd 0:0:1:0\u001b[0m: [sda] Mode Sense: 1f 00 00 08\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33msd 0:0:1:0\u001b[0m: [sda] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mixgbevf\u001b[0m: Intel(R) 10 Gigabit PCI Express Virtual Function Network Driver\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mixgbevf\u001b[0m: Copyright (c) 2009 - 2018 Intel Corporation.\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0mVMware vmxnet3 virtual NIC driver - version 1.6.0.0-k-NAPI\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mhv_vmbus\u001b[0m: registering driver hv_netvsc\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mi8042\u001b[0m: PNP: PS/2 Controller [PNP0303:KBD,PNP0f13:MOU] at 0x60,0x64 irq 1,12\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mi8042\u001b[0m\u001b[1m: Warning: Keylock active\u001b[0m\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mserio\u001b[0m: i8042 KBD port at 0x60,0x64 irq 1\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mserio\u001b[0m: i8042 AUX port at 0x60,0x64 irq 12\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mhv_vmbus\u001b[0m: registering driver hyperv_keyboard\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mrtc_cmos 00:00\u001b[0m: RTC can wake from S4\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mrtc_cmos 00:00\u001b[0m: registered as rtc0\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33m sda\u001b[0m: sda1 sda2 sda3 sda4 sda5 sda6 sda7 sda8 sda9 sda10 sda11 sda12\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33mrtc_cmos 00:00\u001b[0m: alarms up to one day, 114 bytes nvram\n",
            "\u001b[32m[Thu Nov 23 07:08:17 2023] \u001b[0m\u001b[33msd 0:0:1:0\u001b[0m: [sda] Attached SCSI disk\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33miTCO_vendor_support\u001b[0m: vendor-support=0\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mdevice-mapper\u001b[0m\u001b[1m: core: CONFIG_IMA_DISABLE_HTABLE is disabled. Duplicate IMA measurements will not be recorded in the IMA log.\u001b[0m\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mdevice-mapper\u001b[0m: ioctl: 4.45.0-ioctl (2021-03-22) initialised: dm-devel@redhat.com\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mintel_pstate\u001b[0m: CPU model not supported\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0mEFI Variables Facility v0.08 2004-May-17\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mpstore\u001b[0m: Registered efi as persistent store backend\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mhv_utils\u001b[0m: Registering HyperV Utility Driver\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mhv_vmbus\u001b[0m: registering driver hv_utils\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mhv_vmbus\u001b[0m: registering driver hv_balloon\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0mMirror/redirect action on\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0mInitializing XFRM netlink socket\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mNET\u001b[0m: Registered PF_INET6 protocol family\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0mSegment Routing with IPv6\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0mIn-situ OAM (IOAM) with IPv6\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mNET\u001b[0m: Registered PF_PACKET protocol family\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mbridge\u001b[0m: filtering via arp/ip/ip6tables is no longer available by default. Update your scripts to load br_netfilter if you need this.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33m9pnet\u001b[0m: Installing 9P2000 support\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mNET\u001b[0m: Registered PF_VSOCK protocol family\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mIPI shorthand broadcast\u001b[0m: enabled\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33msched_clock\u001b[0m: Marking stable (879199640, 148174670)->(1041755560, -14381250)\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0mregistered taskstats version 1\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0mLoading compiled-in X.509 certificates\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mLoaded X.509 cert 'Google LLC\u001b[0m: Container-Optimized OS kernel signing key: 8a39afb854268005f88bbf8af77608c8729cbb95'\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mLoaded X.509 cert 'Google\u001b[0m: Container-Optimized OS: 2efea493fc148b35859d0bc8c3dd71a139fc7ab411283e06f6c10b5a6b17e355'\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mpstore\u001b[0m: Using crash dump compression: deflate\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mAppArmor\u001b[0m: AppArmor sha1 policy hashing enabled\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mintegrity\u001b[0m: Loading X.509 certificate: UEFI:db\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mintegrity\u001b[0m: Loaded X.509 cert 'Google LLC.: UEFI DB Key v10: 4b4eb27158d8dd4a5bb760f5677f184708c15fdaf94d830a7e59c94b065a2724'\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mima\u001b[0m: Allocated hash algorithm: sha256\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mima\u001b[0m\u001b[31m: Can not allocate sha384 (reason: -2)\u001b[0m\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mima\u001b[0m: No architecture policies found\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mPM\u001b[0m:   Magic number: 15:564:117\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mdevice-mapper\u001b[0m: init: waiting for all devices to be available before creating mapped devices\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33minput\u001b[0m: AT Translated Set 2 keyboard as /devices/platform/i8042/serio0/input/input2\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mdevice-mapper\u001b[0m: verity: sha256 using implementation \"sha256-generic\"\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mdevice-mapper\u001b[0m: ioctl: dm-0 (vroot) is ready\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mmd\u001b[0m: Waiting for all devices to be available before autodetect\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mmd\u001b[0m: If you don't use raid, use raid=noautodetect\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mmd\u001b[0m: Autodetecting RAID arrays.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mmd\u001b[0m: autorun ...\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mmd\u001b[0m: ... autorun DONE.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mEXT4-fs (dm-0)\u001b[0m: mounting ext2 file system using the ext4 subsystem\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mEXT4-fs (dm-0)\u001b[0m: mounted filesystem without journal. Opts: (null). Quota mode: none.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mVFS\u001b[0m: Mounted root (ext2 filesystem) readonly on device 253:0.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mdevtmpfs\u001b[0m: mounted\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: dm-0 (253:0): read-only\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: load pinning engaged.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: x509-certificate pinned obj=\"/etc/ima/pubkey.x509\" pid=1 cmdline=\"\"\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mintegrity\u001b[0m: Loading X.509 certificate: /etc/ima/pubkey.x509\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mintegrity\u001b[0m: Loaded X.509 cert 'Google LLC: Container-Optimized OS kernel signing key: 8a39afb854268005f88bbf8af77608c8729cbb95'\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mFreeing unused decrypted memory\u001b[0m: 2036K\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mFreeing unused kernel image (initmem) memory\u001b[0m: 2156K\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mWrite protecting the kernel read-only data\u001b[0m: 22528k\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mFreeing unused kernel image (text/rodata gap) memory\u001b[0m: 2032K\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33mFreeing unused kernel image (rodata/data gap) memory\u001b[0m: 76K\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0mRun /usr/lib/systemd/systemd as init process\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m  with arguments:\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m    /usr/lib/systemd/systemd\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m    noresume\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m    cros_efi\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m  with environment:\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m    HOME=/\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m    TERM=linux\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m    BOOT_IMAGE=/syslinux/vmlinuz.A\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m    boot=local\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m    modules-load=loadpin_trigger\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: systemd 252 running in system mode (+PAM +AUDIT -SELINUX +APPARMOR +IMA +SMACK +SECCOMP +GCRYPT -GNUTLS +OPENSSL -ACL +BLKID -CURL -ELFUTILS -FIDO2 -IDN2 -IDN -IPTC +KMOD -LIBCRYPTSETUP +LIBFDISK -PCRE2 -PWQUALITY -P11KIT -QRENCODE -TPM2 -BZIP2 +LZ4 -XZ -ZLIB -ZSTD -BPF_FRAMEWORK -XKBCOMMON +UTMP +SYSVINIT default-hierarchy=unified)\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Detected virtualization kvm.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Detected architecture x86-64.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Initializing machine ID from VM UUID.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Installed transient /etc/machine-id file.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m\u001b[1m: Configuration file /usr/lib/systemd/system/systemd-tmpfiles-clean.timer is marked world-inaccessible. This has no effect as configuration data is accessible via APIs without restrictions. Proceeding anyway.\u001b[0m\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m\u001b[1m: Configuration file /usr/lib/systemd/system/crash-sender.timer is marked world-inaccessible. This has no effect as configuration data is accessible via APIs without restrictions. Proceeding anyway.\u001b[0m\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Queued start job for default target multi-user.target.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Created slice system-getty.slice.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Created slice system-modprobe.slice.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Created slice system-serial\\x2dgetty.slice.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Created slice system-sysdaemons.slice.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Created slice system-systemd\\x2dfsck.slice.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Created slice user.slice.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Started systemd-ask-password-console.path.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Started systemd-ask-password-wall.path.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Set up automount proc-sys-fs-binfmt_misc.automount.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Reached target paths.target.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Reached target remote-fs.target.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Reached target slices.target.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Reached target swap.target.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Listening on systemd-coredump.socket.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Listening on systemd-initctl.socket.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Listening on systemd-journald-audit.socket.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Listening on systemd-journald-dev-log.socket.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Listening on systemd-journald.socket.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Listening on systemd-networkd.socket.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Listening on systemd-udevd-control.socket.\n",
            "\u001b[32m[Thu Nov 23 07:08:18 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Listening on systemd-udevd-kernel.socket.\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Mounting dev-hugepages.mount...\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Mounting dev-mqueue.mount...\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Mounting mnt-disks.mount...\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Mounting sys-kernel-debug.mount...\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Mounting sys-kernel-tracing.mount...\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Mounting tmp.mount...\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Starting dev-shm-remount.service...\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Starting kmod-static-nodes.service...\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Starting modprobe@configfs.service...\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: kernel-module pinning-excluded obj=\"/lib/modules/5.15.120+/kernel/fs/configfs/configfs.ko\" pid=139 cmdline=\"/sbin/modprobe -abq configfs\"\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Starting modprobe@drm.service...\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Starting modprobe@efi_pstore.service...\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Starting modprobe@fuse.service...\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: kernel-module pinning-excluded obj=\"/lib/modules/5.15.120+/kernel/fs/fuse/fuse.ko\" pid=143 cmdline=\"/sbin/modprobe -abq fuse\"\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33mfuse\u001b[0m: init (API version 7.34)\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Starting setup-install-attributes.service...\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Starting systemd-journald.service...\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Starting systemd-modules-load.service...\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Starting systemd-remount-fs.service...\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: systemd-repart.service was skipped because no trigger condition checks were met.\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: kernel-module pinning-excluded obj=\"/lib/modules/5.15.120+/misc/loadpin_trigger.ko\" pid=146 cmdline=\"/usr/lib/systemd/systemd-modules-load\"\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33mloadpin_trigger\u001b[0m\u001b[1m: loading out-of-tree module taints kernel.\u001b[0m\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Starting systemd-udev-trigger.service...\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Mounted dev-hugepages.mount.\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Mounted dev-mqueue.mount.\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Mounted mnt-disks.mount.\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33msystemd[1]\u001b[0m: Started systemd-journald.service.\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: kernel-module pinning-excluded obj=\"/lib/modules/5.15.120+/kernel/crypto/cryptd.ko\" pid=201 cmdline=\"/usr/lib/systemd/systemd-udevd\"\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: kernel-module pinning-excluded obj=\"/lib/modules/5.15.120+/kernel/crypto/cryptd.ko\" pid=172 cmdline=\"/usr/lib/systemd/systemd-udevd\"\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33mcryptd\u001b[0m: max_cpu_qlen set to 1000\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: kernel-module pinning-excluded obj=\"/lib/modules/5.15.120+/kernel/crypto/crypto_simd.ko\" pid=172 cmdline=\"/usr/lib/systemd/systemd-udevd\"\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: kernel-module pinning-excluded obj=\"/lib/modules/5.15.120+/kernel/crypto/crypto_simd.ko\" pid=201 cmdline=\"/usr/lib/systemd/systemd-udevd\"\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: kernel-module pinning-excluded obj=\"/lib/modules/5.15.120+/kernel/arch/x86/crypto/aesni-intel.ko\" pid=172 cmdline=\"/usr/lib/systemd/systemd-udevd\"\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: kernel-module pinning-excluded obj=\"/lib/modules/5.15.120+/kernel/arch/x86/crypto/aesni-intel.ko\" pid=201 cmdline=\"/usr/lib/systemd/systemd-udevd\"\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33mEXT4-fs (sda8)\u001b[0m: mounted filesystem with ordered data mode. Opts: (null). Quota mode: none.\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0mAVX2 version of gcm_enc/dec engaged.\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0mAES CTR mode by8 optimization enabled\n",
            "\u001b[32m[Thu Nov 23 07:08:19 2023] \u001b[0m\u001b[33mEXT4-fs (sda1)\u001b[0m: mounted filesystem with ordered data mode. Opts: commit=30. Quota mode: none.\n",
            "\u001b[32m[Thu Nov 23 07:08:20 2023] \u001b[0m\u001b[33msystemd-journald[145]\u001b[0m: Received client request to flush runtime journal.\n",
            "\u001b[32m[Thu Nov 23 07:08:20 2023] \u001b[0m\u001b[33mEXT4-fs (sda1)\u001b[0m: re-mounted. Opts: commit=30. Quota mode: none.\n",
            "\u001b[32m[Thu Nov 23 07:08:20 2023] \u001b[0m\u001b[33mEXT4-fs (sda1)\u001b[0m: re-mounted. Opts: commit=30. Quota mode: none.\n",
            "\u001b[32m[Thu Nov 23 07:08:20 2023] \u001b[0m\u001b[33mEXT4-fs (sda1)\u001b[0m: re-mounted. Opts: commit=30. Quota mode: none.\n",
            "\u001b[32m[Thu Nov 23 07:08:20 2023] \u001b[0m\u001b[33mEXT4-fs (sda1)\u001b[0m: re-mounted. Opts: commit=30. Quota mode: none.\n",
            "\u001b[32m[Thu Nov 23 07:08:20 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: kernel-module pinning-excluded obj=\"/lib/modules/5.15.120+/kernel/net/netfilter/xt_state.ko\" pid=351 cmdline=\"/sbin/modprobe -q -- ipt_state\"\n",
            "\u001b[32m[Thu Nov 23 07:08:23 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: kernel-module pinning-excluded obj=\"/lib/modules/5.15.120+/kernel/net/bridge/br_netfilter.ko\" pid=543 cmdline=\"modprobe -va bridge br_netfilter\"\n",
            "\u001b[32m[Thu Nov 23 07:08:23 2023] \u001b[0mBridge firewalling registered\n",
            "\u001b[32m[Thu Nov 23 07:08:23 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: kernel-module pinning-excluded obj=\"/lib/modules/5.15.120+/kernel/net/netfilter/xt_addrtype.ko\" pid=547 cmdline=\"/sbin/modprobe -q -- ipt_addrtype\"\n",
            "\u001b[32m[Thu Nov 23 07:08:23 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: kernel-module pinning-excluded obj=\"/lib/modules/5.15.120+/kernel/net/netfilter/nf_nat.ko\" pid=549 cmdline=\"/sbin/modprobe -q -- iptable_nat\"\n",
            "\u001b[32m[Thu Nov 23 07:08:23 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: kernel-module pinning-excluded obj=\"/lib/modules/5.15.120+/kernel/net/ipv4/netfilter/iptable_nat.ko\" pid=549 cmdline=\"/sbin/modprobe -q -- iptable_nat\"\n",
            "\u001b[32m[Thu Nov 23 07:08:23 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: kernel-module pinning-excluded obj=\"/lib/modules/5.15.120+/kernel/net/netfilter/xt_MASQUERADE.ko\" pid=581 cmdline=\"/sbin/modprobe -q -- ipt_MASQUERADE\"\n",
            "\u001b[32m[Thu Nov 23 07:08:26 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: kernel-module pinning-excluded obj=\"/lib/modules/5.15.120+/kernel/net/sched/sch_htb.ko\" pid=744 cmdline=\"/sbin/modprobe -q -- sch_htb\"\n",
            "\u001b[32m[Thu Nov 23 07:08:26 2023] \u001b[0m\u001b[33mHTB\u001b[0m\u001b[1m: quantum of class 10001 is big. Consider r2q change.\u001b[0m\n",
            "\u001b[32m[Thu Nov 23 07:08:26 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: kernel-module pinning-excluded obj=\"/lib/modules/5.15.120+/kernel/net/sched/cls_u32.ko\" pid=748 cmdline=\"/sbin/modprobe -q -- cls_u32\"\n",
            "\u001b[32m[Thu Nov 23 07:08:26 2023] \u001b[0mu32 classifier\n",
            "\u001b[32m[Thu Nov 23 07:08:26 2023] \u001b[0m    input device check on\n",
            "\u001b[32m[Thu Nov 23 07:08:26 2023] \u001b[0m    Actions configured\n",
            "\u001b[32m[Thu Nov 23 07:08:27 2023] \u001b[0m\u001b[33mloop0\u001b[0m: detected capacity change from 0 to 167772160\n",
            "\u001b[32m[Thu Nov 23 07:08:27 2023] \u001b[0m\u001b[33mEXT4-fs (loop0)\u001b[0m: mounted filesystem with ordered data mode. Opts: (null). Quota mode: none.\n",
            "\u001b[32m[Thu Nov 23 07:08:27 2023] \u001b[0m\u001b[33mEXT4-fs (sda1)\u001b[0m: re-mounted. Opts: commit=30. Quota mode: none.\n",
            "\u001b[32m[Thu Nov 23 07:08:28 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: kernel-module pinning-excluded obj=\"/lib/modules/5.15.120+/kernel/fs/fat/fat.ko\" pid=911 cmdline=\"/sbin/modprobe -q -- fs-vfat\"\n",
            "\u001b[32m[Thu Nov 23 07:08:28 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: kernel-module pinning-excluded obj=\"/lib/modules/5.15.120+/kernel/fs/fat/vfat.ko\" pid=911 cmdline=\"/sbin/modprobe -q -- fs-vfat\"\n",
            "\u001b[32m[Thu Nov 23 07:08:28 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: kernel-module pinning-excluded obj=\"/lib/modules/5.15.120+/kernel/fs/nls/nls_cp437.ko\" pid=912 cmdline=\"/sbin/modprobe -q -- nls_cp437\"\n",
            "\u001b[32m[Thu Nov 23 07:08:28 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: kernel-module pinning-excluded obj=\"/lib/modules/5.15.120+/kernel/fs/nls/nls_iso8859-1.ko\" pid=913 cmdline=\"/sbin/modprobe -q -- nls_iso8859-1\"\n",
            "\u001b[32m[Thu Nov 23 07:08:29 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: kernel-module pinning-excluded obj=\"/usr/local/nvidia/drivers/nvidia.ko\" pid=927 cmdline=\"insmod /usr/local/nvidia/drivers/nvidia.ko\"\n",
            "\u001b[32m[Thu Nov 23 07:08:29 2023] \u001b[0m\u001b[33mnvidia\u001b[0m\u001b[1m: module license 'NVIDIA' taints kernel.\u001b[0m\n",
            "\u001b[32m[Thu Nov 23 07:08:29 2023] \u001b[0m\u001b[1mDisabling lock debugging due to kernel taint\u001b[0m\n",
            "\u001b[32m[Thu Nov 23 07:08:29 2023] \u001b[0m\u001b[33mnvidia\u001b[0m: module verification failed: signature and/or required key missing - tainting kernel\n",
            "\u001b[32m[Thu Nov 23 07:08:29 2023] \u001b[0m\u001b[33mnvidia-nvlink\u001b[0m: Nvlink Core is being initialized, major device number 244\n",
            "\n",
            "\u001b[32m[Thu Nov 23 07:08:29 2023] \u001b[0m\u001b[33mACPI\u001b[0m: \\_SB_.LNKD: Enabled at IRQ 11\n",
            "\u001b[32m[Thu Nov 23 07:08:29 2023] \u001b[0m\u001b[33mNVRM\u001b[0m\u001b[1m: loading NVIDIA UNIX x86_64 Kernel Module  525.105.17  Tue Mar 28 18:02:59 UTC 2023\u001b[0m\n",
            "\u001b[32m[Thu Nov 23 07:08:29 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: kernel-module pinning-excluded obj=\"/usr/local/nvidia/drivers/nvidia-uvm.ko\" pid=932 cmdline=\"insmod /usr/local/nvidia/drivers/nvidia-uvm.ko\"\n",
            "\u001b[32m[Thu Nov 23 07:08:29 2023] \u001b[0m\u001b[33mnvidia_uvm\u001b[0m\u001b[1m: module uses symbols from proprietary module nvidia, inheriting taint.\u001b[0m\n",
            "\u001b[32m[Thu Nov 23 07:08:29 2023] \u001b[0m\u001b[33mnvidia-uvm\u001b[0m: Loaded the UVM driver, major device number 242.\n",
            "\u001b[32m[Thu Nov 23 07:08:29 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: kernel-module pinning-excluded obj=\"/usr/local/nvidia/drivers/nvidia-drm.ko\" pid=938 cmdline=\"insmod /usr/local/nvidia/drivers/nvidia-drm.ko\"\n",
            "\u001b[32m[Thu Nov 23 07:08:32 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: kernel-module pinning-excluded obj=\"/lib/modules/5.15.120+/kernel/net/netfilter/xt_nat.ko\" pid=989 cmdline=\"/sbin/modprobe -q -- ipt_DNAT\"\n",
            "\u001b[32m[Thu Nov 23 07:08:33 2023] \u001b[0m\u001b[33mLoadPin\u001b[0m: kernel-module pinning-excluded obj=\"/lib/modules/5.15.120+/kernel/drivers/net/veth.ko\" pid=1129 cmdline=\"/sbin/modprobe -q -- rtnl-link-veth\"\n",
            "\u001b[32m[Thu Nov 23 07:08:33 2023] \u001b[0m\u001b[33mbr0\u001b[0m: port 1(veth5e94aa7) entered blocking state\n",
            "\u001b[32m[Thu Nov 23 07:08:33 2023] \u001b[0m\u001b[33mbr0\u001b[0m: port 1(veth5e94aa7) entered disabled state\n",
            "\u001b[32m[Thu Nov 23 07:08:33 2023] \u001b[0mdevice veth5e94aa7 entered promiscuous mode\n",
            "\u001b[32m[Thu Nov 23 07:08:33 2023] \u001b[0m\u001b[33mbr0\u001b[0m: port 2(veth6754229) entered blocking state\n",
            "\u001b[32m[Thu Nov 23 07:08:33 2023] \u001b[0m\u001b[33mbr0\u001b[0m: port 2(veth6754229) entered disabled state\n",
            "\u001b[32m[Thu Nov 23 07:08:33 2023] \u001b[0mdevice veth6754229 entered promiscuous mode\n",
            "\u001b[32m[Thu Nov 23 07:08:33 2023] \u001b[0m\u001b[33mbr0\u001b[0m: port 2(veth6754229) entered blocking state\n",
            "\u001b[32m[Thu Nov 23 07:08:33 2023] \u001b[0m\u001b[33mbr0\u001b[0m: port 2(veth6754229) entered forwarding state\n",
            "\u001b[32m[Thu Nov 23 07:08:33 2023] \u001b[0m\u001b[33mbr0\u001b[0m: port 2(veth6754229) entered disabled state\n",
            "\u001b[32m[Thu Nov 23 07:08:34 2023] \u001b[0m\u001b[33meth0\u001b[0m: renamed from veth507564d\n",
            "\u001b[32m[Thu Nov 23 07:08:34 2023] \u001b[0m\u001b[33mIPv6\u001b[0m: ADDRCONF(NETDEV_CHANGE): veth6754229: link becomes ready\n",
            "\u001b[32m[Thu Nov 23 07:08:34 2023] \u001b[0m\u001b[33mbr0\u001b[0m: port 2(veth6754229) entered blocking state\n",
            "\u001b[32m[Thu Nov 23 07:08:34 2023] \u001b[0m\u001b[33mbr0\u001b[0m: port 2(veth6754229) entered forwarding state\n",
            "\u001b[32m[Thu Nov 23 07:08:34 2023] \u001b[0m\u001b[33mIPv6\u001b[0m: ADDRCONF(NETDEV_CHANGE): br0: link becomes ready\n",
            "\u001b[32m[Thu Nov 23 07:08:34 2023] \u001b[0m\u001b[33meth0\u001b[0m: renamed from veth984aab0\n",
            "\u001b[32m[Thu Nov 23 07:08:34 2023] \u001b[0m\u001b[33mIPv6\u001b[0m: ADDRCONF(NETDEV_CHANGE): veth5e94aa7: link becomes ready\n",
            "\u001b[32m[Thu Nov 23 07:08:34 2023] \u001b[0m\u001b[33mbr0\u001b[0m: port 1(veth5e94aa7) entered blocking state\n",
            "\u001b[32m[Thu Nov 23 07:08:34 2023] \u001b[0m\u001b[33mbr0\u001b[0m: port 1(veth5e94aa7) entered forwarding state\n",
            "\u001b[32m[Thu Nov 23 07:12:11 2023] \u001b[0m\u001b[33mbr0\u001b[0m: port 1(veth5e94aa7) entered disabled state\n",
            "\u001b[32m[Thu Nov 23 07:12:11 2023] \u001b[0m\u001b[33mveth984aab0\u001b[0m: renamed from eth0\n",
            "\u001b[32m[Thu Nov 23 07:12:11 2023] \u001b[0m\u001b[33mbr0\u001b[0m: port 1(veth5e94aa7) entered disabled state\n",
            "\u001b[32m[Thu Nov 23 07:12:11 2023] \u001b[0mdevice veth5e94aa7 left promiscuous mode\n",
            "\u001b[32m[Thu Nov 23 07:12:11 2023] \u001b[0m\u001b[33mbr0\u001b[0m: port 1(veth5e94aa7) entered disabled state\n",
            "\u001b[32m[Thu Nov 23 07:33:29 2023] \u001b[0m\u001b[33mprintk\u001b[0m\u001b[1m: dmesg (63685): Attempt to access syslog with CAP_SYS_ADMIN but no CAP_SYSLOG (deprecated).\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Train the NMT model\n",
        "!onmt_train -config config.yaml --train_from models/model.fren_step_20000.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPIX4W-jrE-z",
        "outputId": "f69e63b4-5e48-42c9-e0d2-fa62bd5fee87"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-23 07:34:27.014052: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-23 07:34:27.014110: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-23 07:34:27.014150: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-23 07:34:27.022677: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-23 07:34:28.214355: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-11-23 07:34:29.279647: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-23 07:34:29.280104: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-23 07:34:29.280287: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "[2023-11-23 07:34:31,107 WARNING] Corpus corpus_1's weight should be given. We default it to 1 for you.\n",
            "[2023-11-23 07:34:31,610 INFO] Parsed 2 corpora from -data.\n",
            "[2023-11-23 07:34:31,611 INFO] Loading checkpoint from models/model.fren_step_20000.pt\n",
            "[2023-11-23 07:34:43,565 INFO] Building model...\n",
            "[2023-11-23 07:34:43,887 INFO] Switching model to float32 for amp/apex_amp\n",
            "[2023-11-23 07:34:43,887 INFO] Non quantized layer compute is fp16\n",
            "[2023-11-23 07:34:52,531 INFO] NMTModel(\n",
            "  (encoder): TransformerEncoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(10000, 512, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding()\n",
            "      )\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (transformer): ModuleList(\n",
            "      (0-5): 6 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TransformerDecoder(\n",
            "    (embeddings): Embeddings(\n",
            "      (make_embedding): Sequential(\n",
            "        (emb_luts): Elementwise(\n",
            "          (0): Embedding(10000, 512, padding_idx=1)\n",
            "        )\n",
            "        (pe): PositionalEncoding()\n",
            "      )\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "    (transformer_layers): ModuleList(\n",
            "      (0-5): 6 x TransformerDecoderLayer(\n",
            "        (self_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (feed_forward): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=512, out_features=2048, bias=False)\n",
            "          (w_2): Linear(in_features=2048, out_features=512, bias=False)\n",
            "          (layer_norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "          (dropout_1): Dropout(p=0.1, inplace=False)\n",
            "          (dropout_2): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (layer_norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (context_attn): MultiHeadedAttention(\n",
            "          (linear_keys): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_values): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (linear_query): Linear(in_features=512, out_features=512, bias=False)\n",
            "          (softmax): Softmax(dim=-1)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (final_linear): Linear(in_features=512, out_features=512, bias=False)\n",
            "        )\n",
            "        (layer_norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (generator): Linear(in_features=512, out_features=10000, bias=True)\n",
            ")\n",
            "[2023-11-23 07:34:52,536 INFO] encoder: 24007680\n",
            "[2023-11-23 07:34:52,536 INFO] decoder: 35435280\n",
            "[2023-11-23 07:34:52,536 INFO] * number of parameters: 59442960\n",
            "[2023-11-23 07:34:52,538 INFO] Trainable parameters = {'torch.float32': 59442960, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2023-11-23 07:34:52,538 INFO] Non trainable parameters = {'torch.float32': 0, 'torch.float16': 0, 'torch.uint8': 0, 'torch.int8': 0}\n",
            "[2023-11-23 07:34:52,538 INFO]  * src vocab size = 10000\n",
            "[2023-11-23 07:34:52,538 INFO]  * tgt vocab size = 10000\n",
            "[2023-11-23 07:34:53,287 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 1\n",
            "[2023-11-23 07:34:53,287 INFO] Starting training on GPU: [0]\n",
            "[2023-11-23 07:34:53,287 INFO] Start training loop and validate every 5000 steps...\n",
            "[2023-11-23 07:34:53,287 INFO] Scoring with: TransformPipe(FilterTooLongTransform(src_seq_length=150, tgt_seq_length=192))\n",
            "[2023-11-23 07:40:32,868 INFO] Saving checkpoint models/model.fren_step_21000.pt\n",
            "[2023-11-23 07:46:29,522 INFO] Saving checkpoint models/model.fren_step_22000.pt\n",
            "[2023-11-23 07:48:51,499 INFO] Step 22500/50000; acc: 56.4; ppl:  23.9; xent: 3.2; lr: 0.00059; sents:  975658; bsz: 3263/3581/98; 38929/42727 tok/s;    838 sec;\n",
            "[2023-11-23 07:51:47,272 INFO] Saving checkpoint models/model.fren_step_23000.pt\n",
            "[2023-11-23 07:57:10,680 INFO] Saving checkpoint models/model.fren_step_24000.pt\n",
            "[2023-11-23 08:03:17,959 INFO] Step 25000/50000; acc: 56.7; ppl:  23.4; xent: 3.2; lr: 0.00056; sents:  977908; bsz: 3264/3580/98; 37676/41320 tok/s;   1705 sec;\n",
            "[2023-11-23 08:03:20,428 INFO] valid stats calculation\n",
            "                           took: 2.4680697917938232 s.\n",
            "[2023-11-23 08:03:20,430 INFO] Train perplexity: 23.6926\n",
            "[2023-11-23 08:03:20,430 INFO] Train accuracy: 56.551\n",
            "[2023-11-23 08:03:20,430 INFO] Sentences processed: 1.95357e+06\n",
            "[2023-11-23 08:03:20,430 INFO] Average bsz: 3264/3581/98\n",
            "[2023-11-23 08:03:20,430 INFO] Validation perplexity: 22.0414\n",
            "[2023-11-23 08:03:20,430 INFO] Validation accuracy: 58.1938\n",
            "[2023-11-23 08:03:20,430 INFO] Model is improving ppl: inf --> 22.0414.\n",
            "[2023-11-23 08:03:20,430 INFO] Model is improving acc: -inf --> 58.1938.\n",
            "[2023-11-23 08:03:20,435 INFO] Saving checkpoint models/model.fren_step_25000.pt\n",
            "[2023-11-23 08:08:31,379 INFO] Saving checkpoint models/model.fren_step_26000.pt\n",
            "[2023-11-23 08:14:41,398 INFO] Saving checkpoint models/model.fren_step_27000.pt\n",
            "[2023-11-23 08:17:50,862 INFO] Step 27500/50000; acc: 57.0; ppl:  23.1; xent: 3.1; lr: 0.00053; sents:  974233; bsz: 3263/3583/97; 37377/41048 tok/s;   2578 sec;\n",
            "[2023-11-23 08:20:00,167 INFO] Saving checkpoint models/model.fren_step_28000.pt\n",
            "[2023-11-23 08:26:03,070 INFO] Saving checkpoint models/model.fren_step_29000.pt\n",
            "[2023-11-23 08:32:18,410 INFO] Step 30000/50000; acc: 57.1; ppl:  23.1; xent: 3.1; lr: 0.00051; sents:  978282; bsz: 3267/3583/98; 37663/41299 tok/s;   3445 sec;\n",
            "[2023-11-23 08:32:18,595 INFO] * Transform statistics for valid(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=5)\n",
            "\n",
            "[2023-11-23 08:32:20,479 INFO] valid stats calculation\n",
            "                           took: 2.066519260406494 s.\n",
            "[2023-11-23 08:32:20,481 INFO] Train perplexity: 23.3794\n",
            "[2023-11-23 08:32:20,481 INFO] Train accuracy: 56.7974\n",
            "[2023-11-23 08:32:20,481 INFO] Sentences processed: 3.90608e+06\n",
            "[2023-11-23 08:32:20,481 INFO] Average bsz: 3264/3582/98\n",
            "[2023-11-23 08:32:20,481 INFO] Validation perplexity: 21.5039\n",
            "[2023-11-23 08:32:20,481 INFO] Validation accuracy: 58.5864\n",
            "[2023-11-23 08:32:20,481 INFO] Model is improving ppl: 22.0414 --> 21.5039.\n",
            "[2023-11-23 08:32:20,481 INFO] Model is improving acc: 58.1938 --> 58.5864.\n",
            "[2023-11-23 08:32:20,486 INFO] Saving checkpoint models/model.fren_step_30000.pt\n",
            "[2023-11-23 08:37:32,015 INFO] Saving checkpoint models/model.fren_step_31000.pt\n",
            "[2023-11-23 08:39:34,477 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=16132)\n",
            "\n",
            "[2023-11-23 08:39:34,477 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 2\n",
            "[2023-11-23 08:43:45,079 INFO] Saving checkpoint models/model.fren_step_32000.pt\n",
            "[2023-11-23 08:46:05,641 INFO] Step 32500/50000; acc: 57.3; ppl:  22.8; xent: 3.1; lr: 0.00049; sents:  974659; bsz: 3263/3583/97; 39447/43312 tok/s;   4272 sec;\n",
            "[2023-11-23 08:49:09,131 INFO] Saving checkpoint models/model.fren_step_33000.pt\n",
            "[2023-11-23 08:55:16,933 INFO] Saving checkpoint models/model.fren_step_34000.pt\n",
            "[2023-11-23 09:00:32,153 INFO] Step 35000/50000; acc: 57.6; ppl:  22.3; xent: 3.1; lr: 0.00047; sents:  978641; bsz: 3267/3579/98; 37703/41306 tok/s;   5139 sec;\n",
            "[2023-11-23 09:00:32,263 INFO] * Transform statistics for valid(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=5)\n",
            "\n",
            "[2023-11-23 09:00:34,064 INFO] valid stats calculation\n",
            "                           took: 1.9094090461730957 s.\n",
            "[2023-11-23 09:00:34,067 INFO] Train perplexity: 23.1011\n",
            "[2023-11-23 09:00:34,067 INFO] Train accuracy: 57.0134\n",
            "[2023-11-23 09:00:34,067 INFO] Sentences processed: 5.85938e+06\n",
            "[2023-11-23 09:00:34,067 INFO] Average bsz: 3265/3582/98\n",
            "[2023-11-23 09:00:34,067 INFO] Validation perplexity: 20.9835\n",
            "[2023-11-23 09:00:34,067 INFO] Validation accuracy: 59.1038\n",
            "[2023-11-23 09:00:34,067 INFO] Model is improving ppl: 21.5039 --> 20.9835.\n",
            "[2023-11-23 09:00:34,067 INFO] Model is improving acc: 58.5864 --> 59.1038.\n",
            "[2023-11-23 09:00:34,075 INFO] Saving checkpoint models/model.fren_step_35000.pt\n",
            "[2023-11-23 09:06:51,094 INFO] Saving checkpoint models/model.fren_step_36000.pt\n",
            "[2023-11-23 09:12:12,643 INFO] Saving checkpoint models/model.fren_step_37000.pt\n",
            "[2023-11-23 09:15:35,621 INFO] Step 37500/50000; acc: 57.8; ppl:  22.1; xent: 3.1; lr: 0.00046; sents:  975316; bsz: 3262/3584/98; 36104/39665 tok/s;   6042 sec;\n",
            "[2023-11-23 09:17:45,307 INFO] Saving checkpoint models/model.fren_step_38000.pt\n",
            "[2023-11-23 09:23:40,438 INFO] Saving checkpoint models/model.fren_step_39000.pt\n",
            "[2023-11-23 09:29:04,403 INFO] Step 40000/50000; acc: 58.0; ppl:  21.8; xent: 3.1; lr: 0.00044; sents:  976888; bsz: 3262/3580/98; 40334/44262 tok/s;   6851 sec;\n",
            "[2023-11-23 09:29:04,518 INFO] * Transform statistics for valid(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=5)\n",
            "\n",
            "[2023-11-23 09:29:05,903 INFO] valid stats calculation\n",
            "                           took: 1.4980368614196777 s.\n",
            "[2023-11-23 09:29:05,905 INFO] Train perplexity: 22.8065\n",
            "[2023-11-23 09:29:05,905 INFO] Train accuracy: 57.2393\n",
            "[2023-11-23 09:29:05,905 INFO] Sentences processed: 7.81158e+06\n",
            "[2023-11-23 09:29:05,905 INFO] Average bsz: 3264/3582/98\n",
            "[2023-11-23 09:29:05,905 INFO] Validation perplexity: 20.7344\n",
            "[2023-11-23 09:29:05,905 INFO] Validation accuracy: 59.323\n",
            "[2023-11-23 09:29:05,905 INFO] Model is improving ppl: 20.9835 --> 20.7344.\n",
            "[2023-11-23 09:29:05,905 INFO] Model is improving acc: 59.1038 --> 59.323.\n",
            "[2023-11-23 09:29:05,909 INFO] Saving checkpoint models/model.fren_step_40000.pt\n",
            "[2023-11-23 09:35:15,031 INFO] Saving checkpoint models/model.fren_step_41000.pt\n",
            "[2023-11-23 09:40:27,708 INFO] Saving checkpoint models/model.fren_step_42000.pt\n",
            "[2023-11-23 09:43:41,962 INFO] Step 42500/50000; acc: 58.0; ppl:  21.9; xent: 3.1; lr: 0.00043; sents:  979195; bsz: 3269/3584/98; 37246/40843 tok/s;   7729 sec;\n",
            "[2023-11-23 09:46:39,328 INFO] Saving checkpoint models/model.fren_step_43000.pt\n",
            "[2023-11-23 09:48:29,360 INFO] * Transform statistics for corpus_1(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=17129)\n",
            "\n",
            "[2023-11-23 09:48:29,360 INFO] Weighted corpora loaded so far:\n",
            "\t\t\t* corpus_1: 3\n",
            "[2023-11-23 09:52:49,401 INFO] Saving checkpoint models/model.fren_step_44000.pt\n",
            "[2023-11-23 09:58:08,494 INFO] Step 45000/50000; acc: 58.2; ppl:  21.6; xent: 3.1; lr: 0.00042; sents:  974750; bsz: 3263/3585/97; 37652/41369 tok/s;   8595 sec;\n",
            "[2023-11-23 09:58:08,602 INFO] * Transform statistics for valid(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=5)\n",
            "\n",
            "[2023-11-23 09:58:10,053 INFO] valid stats calculation\n",
            "                           took: 1.5574164390563965 s.\n",
            "[2023-11-23 09:58:10,054 INFO] Train perplexity: 22.5939\n",
            "[2023-11-23 09:58:10,054 INFO] Train accuracy: 57.4088\n",
            "[2023-11-23 09:58:10,054 INFO] Sentences processed: 9.76553e+06\n",
            "[2023-11-23 09:58:10,054 INFO] Average bsz: 3264/3582/98\n",
            "[2023-11-23 09:58:10,055 INFO] Validation perplexity: 20.3433\n",
            "[2023-11-23 09:58:10,055 INFO] Validation accuracy: 59.649\n",
            "[2023-11-23 09:58:10,055 INFO] Model is improving ppl: 20.7344 --> 20.3433.\n",
            "[2023-11-23 09:58:10,055 INFO] Model is improving acc: 59.323 --> 59.649.\n",
            "[2023-11-23 09:58:10,059 INFO] Saving checkpoint models/model.fren_step_45000.pt\n",
            "[2023-11-23 10:04:13,594 INFO] Saving checkpoint models/model.fren_step_46000.pt\n",
            "[2023-11-23 10:09:36,731 INFO] Saving checkpoint models/model.fren_step_47000.pt\n",
            "[2023-11-23 10:12:47,569 INFO] Step 47500/50000; acc: 58.4; ppl:  21.4; xent: 3.1; lr: 0.00041; sents:  975863; bsz: 3267/3580/98; 37162/40728 tok/s;   9474 sec;\n",
            "[2023-11-23 10:15:48,965 INFO] Saving checkpoint models/model.fren_step_48000.pt\n",
            "[2023-11-23 10:21:09,061 INFO] Saving checkpoint models/model.fren_step_49000.pt\n",
            "[2023-11-23 10:27:14,903 INFO] Step 50000/50000; acc: 58.5; ppl:  21.2; xent: 3.1; lr: 0.00040; sents:  977894; bsz: 3264/3586/98; 37634/41341 tok/s;  10342 sec;\n",
            "[2023-11-23 10:27:15,021 INFO] * Transform statistics for valid(100.00%):\n",
            "\t\t\t* FilterTooLongStats(filtered=5)\n",
            "\n",
            "[2023-11-23 10:27:16,657 INFO] valid stats calculation\n",
            "                           took: 1.7520508766174316 s.\n",
            "[2023-11-23 10:27:16,659 INFO] Train perplexity: 22.3768\n",
            "[2023-11-23 10:27:16,660 INFO] Train accuracy: 57.5801\n",
            "[2023-11-23 10:27:16,660 INFO] Sentences processed: 1.17193e+07\n",
            "[2023-11-23 10:27:16,660 INFO] Average bsz: 3264/3582/98\n",
            "[2023-11-23 10:27:16,660 INFO] Validation perplexity: 20.1755\n",
            "[2023-11-23 10:27:16,660 INFO] Validation accuracy: 59.7669\n",
            "[2023-11-23 10:27:16,660 INFO] Model is improving ppl: 20.3433 --> 20.1755.\n",
            "[2023-11-23 10:27:16,660 INFO] Model is improving acc: 59.649 --> 59.7669.\n",
            "[2023-11-23 10:27:16,667 INFO] Saving checkpoint models/model.fren_step_50000.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!onmt_translate -model models/model.fren_step_50000.pt -src EUbookshop.en-nl.en-filtered.en.subword.test -output UN.nl.translated -gpu 0 -min_length 1"
      ],
      "metadata": {
        "id": "FcYfshBLbGPy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c770c2b1-ec3d-422c-ad9b-ee7b016bae0a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-23 10:48:04.845865: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-23 10:48:04.845923: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-23 10:48:04.845963: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-23 10:48:04.854052: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-23 10:48:06.661134: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-11-23 10:48:08.449370: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-23 10:48:08.449886: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-11-23 10:48:08.450079: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "[2023-11-23 10:48:09,088 INFO] Loading checkpoint from models/model.fren_step_50000.pt\n",
            "[2023-11-23 10:48:11,188 INFO] Loading data into the model\n",
            "[2023-11-23 10:49:11,246 INFO] PRED SCORE: -0.4396, PRED PPL: 1.55 NB SENTENCES: 2000\n",
            "Time w/o python interpreter load/terminate:  62.193035364151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Check the first 5 lines of the translation file\n",
        "!head -n 5 UN.nl.translated"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhDPZi__rIc4",
        "outputId": "88bd53e6-363f-41f5-edc3-2998a7ebbfab"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "▁De ▁beschikbare ▁middelen ▁zullen ▁intern ▁worden ▁verdeeld ▁onder ▁de ▁volgende ▁beperkingen :\n",
            "▁Maar ▁het ▁Europees ▁Parlement ▁zal ▁zich ▁niet ▁laten ▁beperken ▁tot ▁de ▁rol ▁van ▁het ▁alleen ▁maar ▁vaststellen ▁dat ▁er ▁een ▁overeenkomst ▁is ▁bereikt , ▁onafhankelijk ▁van ▁zichzelf .\n",
            "▁De ▁volgende ▁analyse ▁geeft ▁een ▁beeld ▁van ▁de ▁huidige ▁situatie ▁van ▁de ▁Gemeenschap ▁in ▁haar ▁geheel ▁en ▁van ▁de ▁Lid - Staten .\n",
            "▁Bron nen ▁van ▁ grafiek en ▁en ▁ kaarten\n",
            "▁Zee p , ▁organische ▁ten s io - actieve ▁produkten , ▁was middelen , ▁ s meer middelen , ▁kunst was , ▁bereid e ▁was , ▁po ets - ▁en ▁onderhoud smiddelen , ▁k aars en ▁en ▁dergelijke ▁artikelen , ▁model le er pa sta ' s , ▁tand technische ▁was pre para ten ▁en ▁tand technische ▁preparaten ▁op ▁basis ▁van ▁g ip s ; ▁met ▁uitzondering ▁van ▁de ▁posten ▁ex ▁ 3 4 0 3 ▁en ▁ 3 4 0 4 , ▁waarvoor ▁de ▁regels ▁hierna ▁worden ▁uiteengezet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If needed install/update sentencepiece\n",
        "!pip3 install --upgrade -q sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwCSwOwXnHaM",
        "outputId": "6e7352f8-0df7-47fe-8c7f-21edccf0a240"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.3 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/1.3 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# If needed install/update sentencepiece\n",
        "!pip3 install --upgrade -q sentencepiece\n",
        "\n",
        "# Desubword the translation file\n",
        "!python3 MT-Preparation/subwording/3-desubword.py target.model UN.nl.translated"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDkq7wa7rMNZ",
        "outputId": "836002c4-6009-4780-e377-74ddc7a9dc21"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done desubwording! Output: UN.nl.translated.desubword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Check the first 5 lines of the desubworded translation file\n",
        "!head -n 5 UN.nl.translated.desubword"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2T09WvQFrMaz",
        "outputId": "56efe43f-4c5d-454d-d8d9-58670ffa0bc8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "De beschikbare middelen zullen intern worden verdeeld onder de volgende beperkingen:\n",
            "Maar het Europees Parlement zal zich niet laten beperken tot de rol van het alleen maar vaststellen dat er een overeenkomst is bereikt, onafhankelijk van zichzelf.\n",
            "De volgende analyse geeft een beeld van de huidige situatie van de Gemeenschap in haar geheel en van de Lid-Staten.\n",
            "Bronnen van grafieken en kaarten\n",
            "Zeep, organische tensio-actieve produkten, wasmiddelen, smeermiddelen, kunstwas, bereide was, poets- en onderhoudsmiddelen, kaarsen en dergelijke artikelen, modelleerpasta's, tandtechnische waspreparaten en tandtechnische preparaten op basis van gips; met uitzondering van de posten ex 3403 en 3404, waarvoor de regels hierna worden uiteengezet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Desubword the target file (reference) of the test dataset\n",
        "# Note: You might as well have split files *before* subwording during dataset preperation,\n",
        "# but sometimes datasets have tokeniztion issues, so this way you are sure the file is really untokenized.\n",
        "!python3 MT-Preparation/subwording/3-desubword.py source.model EUbookshop.en-nl.en-filtered.en.subword.test\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXtcb131rP5M",
        "outputId": "7deb42c0-9397-42c3-d194-617afc54a299"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done desubwording! Output: EUbookshop.en-nl.en-filtered.en.subword.test.desubword\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python3 MT-Preparation/subwording/3-desubword.py source.model EUbookshop.en-nl.en-filtered.en.subword.test.desubword\n",
        "\n",
        "# Check the first 5 lines of the desubworded reference\n",
        "!head -n 5 /content/drive/MyDrive/nmt/EUbookshop.en-nl.en-filtered.en.subword.test.desubword"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QvUJRKtrQIa",
        "outputId": "f6b286ed-bee8-4424-a2ad-b22910c980ad"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done desubwording! Output: EUbookshop.en-nl.en-filtered.en.subword.test.desubword.desubword\n",
            "The funds available will be broken down internally subject to the following restrictions:\n",
            "But the European Parliament will not allow itself to be reduced to the role of merely having to note that an agreement has been reached independently of itself.\n",
            "The following analysis sheds some light on the current account positions of the Community as a whole and the Member States.\n",
            "Sources of Graphs and Maps\n",
            "Soap, organic surface-active agents, washing preparations, lubricating preparations, artificial waxes, prepared waxes, polishing or scouring preparations, candles and similar articles, modelling pastes, \"dental waxes\" and dental preparations with a basis of plaster; except for heading Nos ex3403 and 3404, for which the rules are set out below\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the BLEU script\n",
        "!wget https://raw.githubusercontent.com/ymoslem/MT-Evaluation/main/BLEU/compute-bleu.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBHJpOcKrcsx",
        "outputId": "3c9f720b-904f-4315-8fe4-628a90eadaa8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-23 10:50:11--  https://raw.githubusercontent.com/ymoslem/MT-Evaluation/main/BLEU/compute-bleu.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 957 [text/plain]\n",
            "Saving to: ‘compute-bleu.py.5’\n",
            "\n",
            "\rcompute-bleu.py.5     0%[                    ]       0  --.-KB/s               \rcompute-bleu.py.5   100%[===================>]     957  --.-KB/s    in 0s      \n",
            "\n",
            "2023-11-23 10:50:11 (34.1 MB/s) - ‘compute-bleu.py.5’ saved [957/957]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install sacrebleu\n",
        "!pip3 install sacrebleu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-Rs837Zrc5_",
        "outputId": "33743a41-0a17-41e8-dd94-086dc259bc1c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.3.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2.8.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.23.5)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the translation (without subwording)\n",
        "!python3 compute-bleu.py EUbookshop.en-nl.en-filtered.en.subword.test.desubword UN.nl.translated.desubword force"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GXAlSwVrdEZ",
        "outputId": "18e24553-8e11-44ce-fe60-e677ae56dc08"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reference 1st sentence: The funds available will be broken down internally subject to the following restrictions:\n",
            "MTed 1st sentence: De beschikbare middelen zullen intern worden verdeeld onder de volgende beperkingen:\n",
            "BLEU:  4.295269576935646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZzzkJgIdoY5",
        "outputId": "ae03fc45-3cfc-4e13-b036-ade68a2cd1e7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate the translation (without subwording)\n",
        "!python3 compute-bleu.py EUbookshop.en-nl.en-filtered.en.subword.test.desubword UN.nl.translated.desubword"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYn9-jXkqslI",
        "outputId": "555c6f83-12ef-4b7c-a0f0-72cdf02347d2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reference 1st sentence: The funds available will be broken down internally subject to the following restrictions:\n",
            "MTed 1st sentence: De beschikbare middelen zullen intern worden verdeeld onder de volgende beperkingen:\n",
            "BLEU:  4.295269576935646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ctranslate2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3V8SvQGsx5A",
        "outputId": "fea59055-99ce-4662-a4e9-edd9c4e9124d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ctranslate2 in /usr/local/lib/python3.10/dist-packages (3.22.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ctranslate2) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2) (1.23.5)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.10/dist-packages (from ctranslate2) (6.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# • OpenNMT-py:\n",
        "!ct2-opennmt-py-converter --model_path /content/drive/MyDrive/nmt/models/model.fren_step_50000.pt --output_dir nlen_ctranslate_new --quantization int8\n"
      ],
      "metadata": {
        "id": "njzGTSPQrwBD"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path\n",
        "import pytesseract\n",
        "import ctranslate2\n",
        "import sentencepiece as spm\n",
        "\n",
        "# Set file paths\n",
        "source_file_path = \"/content/drive/MyDrive/nmt/en-test.txt\" # this is the file you want to translate\n",
        "target_file_path = \"/content/drive/MyDrive/nmt/output.txt\" # this is where you want the translation to be stored\n",
        "\n",
        "\n",
        "sp_source_model_path = \"/content/drive/MyDrive/nmt/source.model\"\n",
        "sp_target_model_path = \"/content/drive/MyDrive/nmt/target.model\"\n",
        "\n",
        "ct_model_path = \"/content/drive/MyDrive/nmt/nlen_ctranslate_new\"\n",
        "\n",
        "\n",
        "# Load the source SentecePiece model\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load(sp_source_model_path)\n",
        "\n",
        "\n",
        "# Open the source file\n",
        "with open(source_file_path, \"r\") as source:\n",
        "  lines = source.readlines() #[:1000]\n",
        "\n",
        "source_sents = [line.strip() for line in lines]\n",
        "\n",
        "# Subword the source sentences\n",
        "source_sents_subworded = sp.encode_as_pieces(source_sents)\n",
        "\n",
        "# Translate the source sentences\n",
        "translator = ctranslate2.Translator(ct_model_path, device=\"cuda\")  # or \"cuda\" for GPU\n",
        "translations = translator.translate_batch(source_sents_subworded, batch_type=\"tokens\", max_batch_size=4096)\n",
        "translations = [translation.hypotheses[0] for translation in translations]\n",
        "\n",
        "# Load the target SentecePiece model\n",
        "sp.load(sp_target_model_path)\n",
        "\n",
        "# Desubword the target sentences\n",
        "translations_desubword = sp.decode(translations)\n",
        "\n",
        "\n",
        "# Save the translations to the a file\n",
        "with open(target_file_path, \"w+\", encoding=\"utf-8\") as target:\n",
        "  for line in translations_desubword:\n",
        "    target.write(line.strip() + \"\\n\")\n",
        "\n",
        "print(\"Done\")"
      ],
      "metadata": {
        "id": "4MJL3J_Srfn3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "096cdcb5-01ea-46cf-92e2-dcf562f52583"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "file_path = \"/content/drive/MyDrive/nmt/en-test.txt\"  # Replace this with your file path\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    content = file.read()\n",
        "    print(content)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avOnIP57SMnN",
        "outputId": "8a4d5130-2837-439a-ba44-9cf1fb574759"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿Computational analysis of emotions has been considered a challenging and inter- esting task. Researchers rely on vari- ous cues such as physiological sensors and facial expressions to identify human emotions. However, there are few prior works who work with textual input to anal- yse these emotions. This survey attempts to summarize these diverse approaches, datasets and resources that have been re- ported for emotional analysis from text. We feel that there is an essential need to have a collective understanding of the re- search in this area. Therefore, we report trends in emotion analysis research. We also present a research matrix that summa- rizes past work, and list pointers to future work. \n",
            "1 Introduction \n",
            "The idea of enabling computers with emotions was first discussed by Picard (1997). This paper ti- tled “Affective Computing” introduces founda- tional ideas in incorporation of affect for comput- ers - from perspectives of both generation and de- tection. Initial research in building affective com- puters focused on human studies that investigate cognition, psychology and behaviors of humans. Such an analysis of emotions from humans of- ten involves use of passive sensors which capture data about the user’s physical state or behavior. The data gathered is analogous to the cues hu- mans use to perceive emotions in others. Picard et al. (2001; Nasoz et al. (2004; Schubert (1999) For example, a video camera can be used to cap- ture facial expressions, body posture and gestures, while a microphone captures speech. Other sen- sors detect emotional cues by directly measuring \n",
            "physiological data, such as skin temperature. Building affective computers requires multi- modal processing since there are a wide variety of cues to be captured. However, in the current scenario, the above-mentioned approaches are im- peded by their requirement of such multi-modal data which may not be readily available. On the contrary, text-based approaches to emotion analy- sis have become popular. In this survey paper, we describe such emotion analysis approaches. The survey paper is aimed at researchers aiming to begin their exploration in emotion analysis. \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/nmt/output.txt\"  # Replace this with your file path\n",
        "\n",
        "with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    content = file.read()\n",
        "    print(content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTj8F6o3SVIZ",
        "outputId": "a799b90b-d7cf-47eb-bd2b-7d1774974326"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In het kader van het onderzoek naar de emotie van emoties is een computatieve analyse van emoties als een uitdaging en een interesterende taak beschouwd: onderzoekers zijn gebaseerd op verschillende cues, zoals fysiologische sensors en facie expressies om de menselijke emoties te identificeren; maar er zijn weinig eerdere werken die met tekstuele input in al deze emoties werken; in deze enquête wordt getracht deze uiteenlopende benaderingen, gegevens en middelen samen te vatten, die voor een fysiologische analyse uit tekst zijn gerapporteerd.\n",
            "1 Inleiding\n",
            "Het idee om computers met emotieven te laten emoties werd voor het eerst besproken door Picard (1997).In dit document “Affectieve Computing” worden gids-ideeën ingebouwd die invloed hebben op computers - vanuit perspectief van zowel generaties als detectie.In eerste onderzoek naar fysische computers gericht op menselijke studies die onderzoek doen naar cognitie, psychologie en dragers van mensen.\n",
            "In het huidige scenario worden deze benaderingen echter geïmplementeerd door hun eis dat dergelijke multimodale gegevens niet gemakkelijk beschikbaar zijn; integendeel, de op de tekst gebaseerde benaderingen van emotie-analysis zijn populair geworden; in dit rapport worden dergelijke emotieanalyse ⁇ en beschreven.\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}