{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1 **Install required packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN_Dzlu6EyTx",
        "outputId": "52c508c0-2d29-4fba-f56b-021388307a86"
      },
      "outputs": [],
      "source": [
        "!pip install openai\n",
        "!pip install pdf2image pytesseract\n",
        "!brew install poppler\n",
        "!apt-get install -y poppler-utils\n",
        "!apt install tesseract-ocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "pJXSQeSxJrVd",
        "outputId": "50d2c3c2-cb93-47fa-eaab-1d2f2bd4ab21"
      },
      "outputs": [],
      "source": [
        "!pip install openai==0.28"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. **Define Summarizer class -- A Input file, B String**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuYhgwKaEV-s",
        "outputId": "62f6afaf-0824-4a31-c5f2-c33e5142ab6d"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "from pdf2image import convert_from_path\n",
        "import pytesseract\n",
        "from tkinter import filedialog\n",
        "\n",
        "class GPTSummarizer:\n",
        "    def __init__(self, api_key, max_input_length=4096):  # Updated default max length for gpt-3.5-turbo\n",
        "        self.api_key = api_key\n",
        "        self.max_input_length = max_input_length\n",
        "        openai.api_key = self.api_key\n",
        "\n",
        "    def _cut_input(self, text):\n",
        "        if len(text) <= self.max_input_length:\n",
        "            return [text]\n",
        "\n",
        "        chunks = []\n",
        "        while len(text) > 0:\n",
        "            chunk = text[:self.max_input_length]\n",
        "            text = text[self.max_input_length:]\n",
        "            chunks.append(chunk)\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    def summarize(self, text):\n",
        "        chunks = self._cut_input(text)\n",
        "        summaries = []\n",
        "        for chunk in chunks:\n",
        "            summarized_chunk = self._summarize_chunk(chunk)\n",
        "            summaries.append(summarized_chunk)\n",
        "        return summaries\n",
        "\n",
        "    def _summarize_chunk(self, text):\n",
        "        messages = [{\"role\": \"system\", \"content\": \"You are a helpful summarizer\"},\n",
        "                    {\"role\": \"user\", \"content\": f\"Summarize the following: {text}\"}]\n",
        "\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=messages\n",
        "        )\n",
        "\n",
        "        return response.choices[0].message['content']\n",
        "\n",
        "\n",
        "    def read_from_file(filename):\n",
        "        with open(filename, 'r', encoding='utf-8') as file:\n",
        "            content = file.read()\n",
        "        return content\n",
        "\n",
        "\n",
        "    def extract_text_from_pdf(pdf_path):\n",
        "        images = convert_from_path(pdf_path)\n",
        "        text = \"\"\n",
        "\n",
        "        for image in images:\n",
        "            text += pytesseract.image_to_string(image)\n",
        "\n",
        "        return text\n",
        "\n",
        "    def is_pdf(file_path):\n",
        "        # Check based on file extension\n",
        "        if not file_path.lower().endswith('.pdf'):\n",
        "            return False\n",
        "\n",
        "        # Check based on file header\n",
        "        with open(file_path, 'rb') as file:\n",
        "            header = file.read(4)\n",
        "        return header == b'%PDF'\n",
        "\n",
        "    def combine_strings(string_list):\n",
        "        return ''.join(string_list)\n",
        "\n",
        "# Test\n",
        "\n",
        "#MEthod return true if given file path is a pdf\n",
        "# is_pdf_file = GPTSummarizer.is_pdf('path_to_your_file')\n",
        "# print(is_pdf_file)  # True if it's a PDF, False otherwise\n",
        "\n",
        "\n",
        "\n",
        "# Method to read a .txt file\n",
        "# file_content = GPTSummarizer.read_from_file('path_to_your_file.txt')\n",
        "# print(file_content)\n",
        "\n",
        "\n",
        "# Method to read a pdf file\n",
        "# pdf_content = GPTSummarizer.extract_text_from_pdf('path_to_your_file.pdf')\n",
        "# print(pdf_content)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#This is for testing put input string here\n",
        "# text_to_summarize = (\"The solar system consists of the Sun and the objects that orbit it.\"\n",
        "#                     \"These objects include planets, moons, asteroids, comets, and more. \"\n",
        "#                     \"The solar system is vast, with the Sun containing over 99.8% of its total mass.\")\n",
        "\n",
        "\n",
        "#text_to_summarize = is where you put the input string for the summarizer\n",
        "# summaries = summarizer.summarize(text_to_summarize)\n",
        "# print(summaries)\n",
        "\n",
        "\n",
        "#to select file from computer\n",
        "#file_path = filedialog.askopenfilename(title=\"Select a document\", filetypes=[(\"PDF files\", \"*.pdf\"), (\"All files\", \"*.*\")])\n",
        "#print(file_path)\n",
        "\n",
        "summarizer = GPTSummarizer('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')\n",
        "\n",
        "\n",
        "#is_pdf_file = GPTSummarizer.is_pdf(file_path)\n",
        "is_pdf_file = GPTSummarizer.is_pdf(\"/content/1981GrahamFourier.pdf\")\n",
        "file_path = \"/content/1981GrahamFourier.pdf\"\n",
        "\n",
        "\n",
        "#This is for when the person want to input the string to be send the summarizer instead of inputing a file\n",
        "input_text = False\n",
        "\n",
        "if input_text:\n",
        "  text = input(\"Input string: \")\n",
        "  try:\n",
        "    summaries = summarizer.summarize(text)\n",
        "    cs = GPTSummarizer.combine_strings(summaries)\n",
        "\n",
        "    print(cs)\n",
        "  except:\n",
        "    print(\"gpt error retrying\")\n",
        "    summaries = summarizer.summarize(text)\n",
        "    cs = GPTSummarizer.combine_strings(summaries)\n",
        "\n",
        "    print(cs)\n",
        "else:\n",
        "\n",
        "  if is_pdf_file:\n",
        "      pdf_content = GPTSummarizer.extract_text_from_pdf(file_path )\n",
        "\n",
        "      print(\"PDF to text complete\")\n",
        "      print(\"-\"*20)\n",
        "      print(pdf_content)\n",
        "      print(\"-\"*20)\n",
        "      try:\n",
        "        summaries = summarizer.summarize(pdf_content)\n",
        "        cs = GPTSummarizer.combine_strings(summaries)\n",
        "\n",
        "        print(cs)\n",
        "      except:\n",
        "        print(\"gpt error retrying\")\n",
        "        summaries = summarizer.summarize(pdf_content)\n",
        "        cs = GPTSummarizer.combine_strings(summaries)\n",
        "\n",
        "        print(cs)\n",
        "\n",
        "  else:\n",
        "      file_content = GPTSummarizer.read_from_file(file_path)\n",
        "      print(file_content)\n",
        "      try:\n",
        "        summaries = summarizer.summarize(file_content)\n",
        "        cs = GPTSummarizer.combine_strings(summaries)\n",
        "\n",
        "        print(cs)\n",
        "      except:\n",
        "        print(\"gpt error retrying\")\n",
        "        summaries = summarizer.summarize(file_content)\n",
        "        cs = GPTSummarizer.combine_strings(summaries)\n",
        "\n",
        "        print(cs)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuZ_3IydLAHm",
        "outputId": "03410211-9da4-4d88-c3ea-20cd27cb4d2c"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O31KUrfNj7my",
        "outputId": "93a41952-1a84-4021-8af6-15b9051161f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['- The human visual system contains multiple spatial-frequency channels, each sensitive to a different range of spatial frequencies in visual patterns.\\n- The existence of visual neurons with different sizes of receptive fields has important implications for pattern vision.\\n- There are multiple size-selective channels in the human visual system.\\n- The visual system does a Fourier analysis of the visual scene.\\n- The history of the multiple-channels model and its current status is reviewed.\\n- Mathematics has played a role in the development of the multiple-channels model and could be further utilized.\\n- The single-channel model of pattern vision developed into the multiple spatial-frequency channels model.\\n- Vertebrate retinal ganglion cells respond to light in a broad area called the \"receptive field.\"\\n- Neurons respond differently depending on where in the receptive field the light falls.\\n- The response of these neurons to light patterns is approximately linear.\\n- The response to two spots of light is approximately equal to the sum of the responses to each spot alone.- Neurons in the visual cortex have receptive fields that respond to specific stimuli\\n- Some cortical cells have rectangular receptive fields with excitatory and inhibitory areas\\n- The Single-Channel Model assumes that the visual system can be modeled as an array of these neurons with overlapping receptive fields\\n- This model is a linear system, and it is supported by behavioral and physiological evidence\\n- Sinusoidal gratings were used as a stimulus to study vision because they can easily vary in contrast and spatial frequency\\n- Fourier analysis can be used to analyze and synthesize visual patterns, including sinusoidal gratings\\n- The response of a linear system to a sinusoidal grating is specific to the frequency and orientation of the grating- The transfer function of a system specifies the amplitude and phase for each frequency-orientation combination in a sinusoid grating.\\n- According to the linear, translation-invariant single-channel model, the response of the visual system to any pattern can be computed from its response to sinusoids using the transfer function.\\n- An array of neurons with antagonistic excitatory and inhibitory areas in their receptive fields responds best to a medium frequency and has limited ranges of spatial frequencies and orientations.\\n- The simplicity of the single-channel model is appealing, but it has been shown to be incorrect.\\n- In an experiment comparing theoretical predictions to experimental results, four patterns were used: two simple sinusoidal gratings of different frequencies and two compound gratings with both frequencies but in different phases.\\n- The detection threshold (contrast at which an observer can just tell that a pattern is present) was measured for each pattern.\\n- The single-channel model predicts how the patterns would be detected by the visual system.- The experiment involves a single-channel model and a multiple-channels model.\\n- The single-channel model predicts that the response to compound gratings will be higher than the response to individual components.\\n- Human observers, however, detect all four patterns equally, which contradicts the single-channel model.\\n- A nonuniform single-channel model, where receptive field size changes from center to periphery, is also ruled out by experimental results.\\n- The multiple-channels model is consistent with the experimental results.\\n- In the multiple-channels model, each channel can have an array of receptive fields of different sizes.\\n- Different channels have different receptive field sizes, with low spatial-frequency channels having larger receptive fields than high spatial-frequency channels.\\n- The compound grating behaves the same as its individual components for each channel.- The model being discussed in this passage is a multiple-channels model for detecting patterns in vision.\\n- The model assumes that the response of at least one channel is sufficient to detect a pattern, regardless of the frequency or phase.\\n- The model predicts that compound gratings (gratings made up of multiple components) are just at threshold and that they are as detectable as their most detectable component.\\n- However, in reality, compound gratings are slightly more detectable than their components, which is explained by the concept of probability summation.\\n- Probability summation suggests that the variability in an observer\\'s response to a stimulus is due to variability in the responses of different channels.\\n- The model also accounts for the variability in responses across the spatial extent of each channel.\\n- Calculations from the multiple-channels model are complicated by the presence of probability summation and the need to account for spatial extent.\\n- A quick pooling model, using the Weibull function, is introduced as a more practical approach to calculating the predictions of the multiple-channels model.\\n- The Weibull function describes the probability that a receptive field detects a stimulus based on its sensitivity and a parameter determining the steepness of the function.- The observer\\'s probability of detecting a pattern, P, can be calculated using the formula P = (1 - 2^(-2.45S)) where S is the sensitivity of the observer to the stimulus.\\n- The assumption is made that when the observer detects the pattern, they always respond correctly, and when they do not detect the pattern, they simply guess.\\n- The psychometric function, which determines the observer\\'s probability of detection, has the same form for every stimulus and receptive field.\\n- Empirically, a value of k of about 3.5 seems to describe the psychometric function for a wide variety of stimuli.\\n- The sensitivity of each receptive field is represented by a point in a metric space, and the distance between points represents the sensitivity to a stimulus.\\n- When k is infinity, the observer\\'s sensitivity equals the sensitivity of the most sensitive unit.\\n- When k is 1, the sensitivities of different units are linearly summed.\\n- When k is 2, there is power summation (which is false in this context).\\n- When k is about 3.5, the expression quantitatively predicts the thresholds for a wide variety of patterns.- A model of probability summation across receptive fields and channels can account for psychometric functions and threshold values for various stimuli.\\n- The nonlinear pooling across receptive fields and channels may not be due to probability summation, and the agreement between the steepness parameter and the exponent needed to account for thresholds may be coincidental.\\n- The metric in the equation for S provides insight into the pooling across receptive fields and channels required to predict thresholds.\\n- There is no evidence for a set of neurons in the brain that performs a strict Fourier analysis of the visual scene.\\n- Historically, none of the mentioned researchers implied that the visual system performs a strict Fourier analysis.\\n- There is accumulating evidence that the brain- The author discusses the concept of crude Fourier analysis, which involves performing operations with characteristics similar to Fourier analysis.\\n- Compound gratings with closely spaced component frequencies suggest a medium bandwidth of 1-2 octaves for each channel.\\n- Sine-plus-sine experiments provide evidence for multiple spatial-frequency channels and their suggested bandwidths.\\n- Adaptation and masking experiments show that the visibility and perceived appearance of test patterns are affected by similar spatial frequencies but not by different frequencies or orientations.\\n- Recognition experiments demonstrate that far-apart frequencies can be recognized while closer frequencies may lead to confusion, indicating medium bandwidths for channels.\\n- Compound gratings with frequencies in a three-to-one ratio can be detected but their relative phase cannot be determined, suggesting the existence of separate channels for each component.\\n- At threshold contrasts, compound gratings can be perceived as a compound, one of its components, the other component, or as a blank.- In texture segregation experiments, observers determine whether there are two different areas with different textures.\\n- Julesz originally believed that only textures with different second-order statistics (autocorrelation functions and amplitude spectra) can be immediately discriminated.\\n- However, Julesz found texture pairs with identical second-order statistics that are discriminable, suggesting the existence of a second class of visual mechanism.\\n- The receptive fields of retinal ganglion cells and neurons in the cortex respond to different ranges of spatial frequencies, indicating the presence of medium bandwidth channels.\\n- Mathematics, particularly Fourier analysis, has been useful in understanding the visual system and the multiple spatial-frequency channels model.\\n- While the channels are not extremely narrowband, considering the Fourier transforms of stimuli and transfer functions in the frequency domain can provide better predictions and calculations.- Fourier analysis can provide a new description of visual stimuli and stimulate creative thought in understanding the visual system.\\n- Spatial-frequency descriptions (Fourier transforms) and point-wise descriptions (intensity as a function of spatial position) emphasize different aspects of the stimulus.\\n- Nonlinear pooling and the Weibull function have been useful in understanding pattern vision and the thresholds for pattern detection.\\n- There is a need for mathematics that can represent medium-bandwidth channels in the visual system and provide more insight into studying them.\\n- More ways to investigate and describe nonlinearities are needed in pattern vision research.\\n- Probability summation is necessary to accurately account for pattern thresholds, as they are determined by nonlinear pooling of channel responses.- The action of a group of channels is important rather than a single channel in responding to a pattern.\\n- The output of a channel seems to be the result of probability summation or nonlinear pooling.\\n- The Quick pooling model does a good job at accounting for threshold data but is not completely correct.\\n- Many neurons in the visual system are linear, but there are also nonlinear cells that are more difficult to understand.\\n- Wiener analysis is being used to make progress in understanding nonlinear cells.\\n- Various references are mentioned that provide further information on the topic.- The listed articles are scientific studies related to vision and perception.\\n- Each article explores different aspects of visual perception, such as discrimination of gratings, contrast detection, spatial summation effects, size-detecting mechanisms, spatial resolution, neural networks in the retina, probability summation, spatial-frequency channels, nonlinear spatial summation, and patterns of temporal interaction in the detection of gratings.\\n- The studies involve experimentation and analysis to understand how the human visual system processes and perceives visual information.\\n- The authors of the articles include various researchers and scientists in the field of vision and perception.\\n- The articles were published in different years and in different scientific journals.']\n"
          ]
        }
      ],
      "source": [
        "from numpy.lib.npyio import savez_compressed\n",
        "import openai\n",
        "from pdf2image import convert_from_path\n",
        "import pytesseract\n",
        "from tkinter import filedialog\n",
        "import os\n",
        "\n",
        "# -- A) Input file\n",
        "\n",
        "class GPTSummarizer:\n",
        "    def __init__(self, api_key, max_input_length=4096):  # Updated default max length for gpt-3.5-turbo\n",
        "        self.api_key = api_key\n",
        "        self.max_input_length = max_input_length\n",
        "        openai.api_key = self.api_key\n",
        "\n",
        "    def _cut_input(self, text):\n",
        "        if len(text) <= self.max_input_length:\n",
        "            return [text]\n",
        "\n",
        "        chunks = []\n",
        "        while len(text) > 0:\n",
        "            chunk = text[:self.max_input_length]\n",
        "            text = text[self.max_input_length:]\n",
        "            chunks.append(chunk)\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    def summarize(self, text):\n",
        "        chunks = self._cut_input(text)\n",
        "        summaries = []\n",
        "        for chunk in chunks:\n",
        "            summarized_chunk = self._summarize_chunk(chunk)\n",
        "            summaries.append(summarized_chunk)\n",
        "        return summaries\n",
        "\n",
        "    def _summarize_chunk(self, text):\n",
        "        messages = [{\"role\": \"system\", \"content\": \"You are a helpful summarizer. Give me bullet point summarization and keypoints to know\"},\n",
        "                    {\"role\": \"user\", \"content\": f\"Summarize the following: {text}\"}]\n",
        "\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=messages\n",
        "        )\n",
        "\n",
        "        return response.choices[0].message['content']\n",
        "\n",
        "\n",
        "    def read_from_file(filename):\n",
        "        with open(filename, 'r', encoding='utf-8') as file:\n",
        "            content = file.read()\n",
        "        return content\n",
        "\n",
        "\n",
        "    def extract_text_from_pdf(pdf_path):\n",
        "        images = convert_from_path(pdf_path)\n",
        "        text = \"\"\n",
        "\n",
        "        for image in images:\n",
        "            text += pytesseract.image_to_string(image)\n",
        "\n",
        "        return text\n",
        "\n",
        "    def is_pdf(file_path):\n",
        "        # Check based on file extension\n",
        "        if not file_path.lower().endswith('.pdf'):\n",
        "            return False\n",
        "\n",
        "        # Check based on file header\n",
        "        with open(file_path, 'rb') as file:\n",
        "            header = file.read(4)\n",
        "        return header == b'%PDF'\n",
        "\n",
        "    def combine_strings(string_list):\n",
        "        return ''.join(string_list)\n",
        "\n",
        "# Test\n",
        "\n",
        "#MEthod return true if given file path is a pdf\n",
        "# is_pdf_file = GPTSummarizer.is_pdf('path_to_your_file')\n",
        "# print(is_pdf_file)  # True if it's a PDF, False otherwise\n",
        "\n",
        "\n",
        "\n",
        "# Method to read a .txt file\n",
        "# file_content = GPTSummarizer.read_from_file('path_to_your_file.txt')\n",
        "# print(file_content)\n",
        "\n",
        "\n",
        "# Method to read a pdf file\n",
        "# pdf_content = GPTSummarizer.extract_text_from_pdf('path_to_your_file.pdf')\n",
        "# print(pdf_content)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#This is for testing put input string here\n",
        "# text_to_summarize = (\"The solar system consists of the Sun and the objects that orbit it.\"\n",
        "#                     \"These objects include planets, moons, asteroids, comets, and more. \"\n",
        "#                     \"The solar system is vast, with the Sun containing over 99.8% of its total mass.\")\n",
        "\n",
        "\n",
        "#text_to_summarize = is where you put the input string for the summarizer\n",
        "# summaries = summarizer.summarize(text_to_summarize)\n",
        "# print(summaries)\n",
        "\n",
        "\n",
        "#to select file from computer\n",
        "#file_path = filedialog.askopenfilename(title=\"Select a document\", filetypes=[(\"PDF files\", \"*.pdf\"), (\"All files\", \"*.*\")])\n",
        "#print(file_path)\n",
        "\n",
        "summarizer = GPTSummarizer('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')\n",
        "\n",
        "\n",
        "#is_pdf_file = GPTSummarizer.is_pdf(file_path)\n",
        "\n",
        "\n",
        "# -- B) This is for when the person want to input the string to be send the summarizer instead of inputing a file\n",
        "input_text = False\n",
        "\n",
        "save = []\n",
        "folder_path = '/content/mytest'\n",
        "filenames = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
        "summarizer = GPTSummarizer('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')\n",
        "\n",
        "for filename in filenames:\n",
        "    file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "\n",
        "    pdf_content = GPTSummarizer.extract_text_from_pdf(file_path)\n",
        "\n",
        "    try:\n",
        "        summaries = summarizer.summarize(pdf_content)\n",
        "        cs = GPTSummarizer.combine_strings(summaries)\n",
        "        save.append(cs)\n",
        "    except:\n",
        "        print(\"GPT error, retrying...\")\n",
        "        summaries = summarizer.summarize(pdf_content)\n",
        "        cs = GPTSummarizer.combine_strings(summaries)\n",
        "        save.append(cs)\n",
        "\n",
        "\n",
        "print(save)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StfSmqZ6T48e",
        "outputId": "bf8f53e6-3988-4f21-f637-f1b5f174a003"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- The human visual system contains multiple spatial-frequency channels, each sensitive to a different range of spatial frequencies in visual patterns.\n",
            "- The existence of visual neurons with different sizes of receptive fields has important implications for pattern vision.\n",
            "- There are multiple size-selective channels in the human visual system.\n",
            "- The visual system does a Fourier analysis of the visual scene.\n",
            "- The history of the multiple-channels model and its current status is reviewed.\n",
            "- Mathematics has played a role in the development of the multiple-channels model and could be further utilized.\n",
            "- The single-channel model of pattern vision developed into the multiple spatial-frequency channels model.\n",
            "- Vertebrate retinal ganglion cells respond to light in a broad area called the \"receptive field.\"\n",
            "- Neurons respond differently depending on where in the receptive field the light falls.\n",
            "- The response of these neurons to light patterns is approximately linear.\n",
            "- The response to two spots of light is approximately equal to the sum of the responses to each spot alone.- Neurons in the visual cortex have receptive fields that respond to specific stimuli\n",
            "- Some cortical cells have rectangular receptive fields with excitatory and inhibitory areas\n",
            "- The Single-Channel Model assumes that the visual system can be modeled as an array of these neurons with overlapping receptive fields\n",
            "- This model is a linear system, and it is supported by behavioral and physiological evidence\n",
            "- Sinusoidal gratings were used as a stimulus to study vision because they can easily vary in contrast and spatial frequency\n",
            "- Fourier analysis can be used to analyze and synthesize visual patterns, including sinusoidal gratings\n",
            "- The response of a linear system to a sinusoidal grating is specific to the frequency and orientation of the grating- The transfer function of a system specifies the amplitude and phase for each frequency-orientation combination in a sinusoid grating.\n",
            "- According to the linear, translation-invariant single-channel model, the response of the visual system to any pattern can be computed from its response to sinusoids using the transfer function.\n",
            "- An array of neurons with antagonistic excitatory and inhibitory areas in their receptive fields responds best to a medium frequency and has limited ranges of spatial frequencies and orientations.\n",
            "- The simplicity of the single-channel model is appealing, but it has been shown to be incorrect.\n",
            "- In an experiment comparing theoretical predictions to experimental results, four patterns were used: two simple sinusoidal gratings of different frequencies and two compound gratings with both frequencies but in different phases.\n",
            "- The detection threshold (contrast at which an observer can just tell that a pattern is present) was measured for each pattern.\n",
            "- The single-channel model predicts how the patterns would be detected by the visual system.- The experiment involves a single-channel model and a multiple-channels model.\n",
            "- The single-channel model predicts that the response to compound gratings will be higher than the response to individual components.\n",
            "- Human observers, however, detect all four patterns equally, which contradicts the single-channel model.\n",
            "- A nonuniform single-channel model, where receptive field size changes from center to periphery, is also ruled out by experimental results.\n",
            "- The multiple-channels model is consistent with the experimental results.\n",
            "- In the multiple-channels model, each channel can have an array of receptive fields of different sizes.\n",
            "- Different channels have different receptive field sizes, with low spatial-frequency channels having larger receptive fields than high spatial-frequency channels.\n",
            "- The compound grating behaves the same as its individual components for each channel.- The model being discussed in this passage is a multiple-channels model for detecting patterns in vision.\n",
            "- The model assumes that the response of at least one channel is sufficient to detect a pattern, regardless of the frequency or phase.\n",
            "- The model predicts that compound gratings (gratings made up of multiple components) are just at threshold and that they are as detectable as their most detectable component.\n",
            "- However, in reality, compound gratings are slightly more detectable than their components, which is explained by the concept of probability summation.\n",
            "- Probability summation suggests that the variability in an observer's response to a stimulus is due to variability in the responses of different channels.\n",
            "- The model also accounts for the variability in responses across the spatial extent of each channel.\n",
            "- Calculations from the multiple-channels model are complicated by the presence of probability summation and the need to account for spatial extent.\n",
            "- A quick pooling model, using the Weibull function, is introduced as a more practical approach to calculating the predictions of the multiple-channels model.\n",
            "- The Weibull function describes the probability that a receptive field detects a stimulus based on its sensitivity and a parameter determining the steepness of the function.- The observer's probability of detecting a pattern, P, can be calculated using the formula P = (1 - 2^(-2.45S)) where S is the sensitivity of the observer to the stimulus.\n",
            "- The assumption is made that when the observer detects the pattern, they always respond correctly, and when they do not detect the pattern, they simply guess.\n",
            "- The psychometric function, which determines the observer's probability of detection, has the same form for every stimulus and receptive field.\n",
            "- Empirically, a value of k of about 3.5 seems to describe the psychometric function for a wide variety of stimuli.\n",
            "- The sensitivity of each receptive field is represented by a point in a metric space, and the distance between points represents the sensitivity to a stimulus.\n",
            "- When k is infinity, the observer's sensitivity equals the sensitivity of the most sensitive unit.\n",
            "- When k is 1, the sensitivities of different units are linearly summed.\n",
            "- When k is 2, there is power summation (which is false in this context).\n",
            "- When k is about 3.5, the expression quantitatively predicts the thresholds for a wide variety of patterns.- A model of probability summation across receptive fields and channels can account for psychometric functions and threshold values for various stimuli.\n",
            "- The nonlinear pooling across receptive fields and channels may not be due to probability summation, and the agreement between the steepness parameter and the exponent needed to account for thresholds may be coincidental.\n",
            "- The metric in the equation for S provides insight into the pooling across receptive fields and channels required to predict thresholds.\n",
            "- There is no evidence for a set of neurons in the brain that performs a strict Fourier analysis of the visual scene.\n",
            "- Historically, none of the mentioned researchers implied that the visual system performs a strict Fourier analysis.\n",
            "- There is accumulating evidence that the brain- The author discusses the concept of crude Fourier analysis, which involves performing operations with characteristics similar to Fourier analysis.\n",
            "- Compound gratings with closely spaced component frequencies suggest a medium bandwidth of 1-2 octaves for each channel.\n",
            "- Sine-plus-sine experiments provide evidence for multiple spatial-frequency channels and their suggested bandwidths.\n",
            "- Adaptation and masking experiments show that the visibility and perceived appearance of test patterns are affected by similar spatial frequencies but not by different frequencies or orientations.\n",
            "- Recognition experiments demonstrate that far-apart frequencies can be recognized while closer frequencies may lead to confusion, indicating medium bandwidths for channels.\n",
            "- Compound gratings with frequencies in a three-to-one ratio can be detected but their relative phase cannot be determined, suggesting the existence of separate channels for each component.\n",
            "- At threshold contrasts, compound gratings can be perceived as a compound, one of its components, the other component, or as a blank.- In texture segregation experiments, observers determine whether there are two different areas with different textures.\n",
            "- Julesz originally believed that only textures with different second-order statistics (autocorrelation functions and amplitude spectra) can be immediately discriminated.\n",
            "- However, Julesz found texture pairs with identical second-order statistics that are discriminable, suggesting the existence of a second class of visual mechanism.\n",
            "- The receptive fields of retinal ganglion cells and neurons in the cortex respond to different ranges of spatial frequencies, indicating the presence of medium bandwidth channels.\n",
            "- Mathematics, particularly Fourier analysis, has been useful in understanding the visual system and the multiple spatial-frequency channels model.\n",
            "- While the channels are not extremely narrowband, considering the Fourier transforms of stimuli and transfer functions in the frequency domain can provide better predictions and calculations.- Fourier analysis can provide a new description of visual stimuli and stimulate creative thought in understanding the visual system.\n",
            "- Spatial-frequency descriptions (Fourier transforms) and point-wise descriptions (intensity as a function of spatial position) emphasize different aspects of the stimulus.\n",
            "- Nonlinear pooling and the Weibull function have been useful in understanding pattern vision and the thresholds for pattern detection.\n",
            "- There is a need for mathematics that can represent medium-bandwidth channels in the visual system and provide more insight into studying them.\n",
            "- More ways to investigate and describe nonlinearities are needed in pattern vision research.\n",
            "- Probability summation is necessary to accurately account for pattern thresholds, as they are determined by nonlinear pooling of channel responses.- The action of a group of channels is important rather than a single channel in responding to a pattern.\n",
            "- The output of a channel seems to be the result of probability summation or nonlinear pooling.\n",
            "- The Quick pooling model does a good job at accounting for threshold data but is not completely correct.\n",
            "- Many neurons in the visual system are linear, but there are also nonlinear cells that are more difficult to understand.\n",
            "- Wiener analysis is being used to make progress in understanding nonlinear cells.\n",
            "- Various references are mentioned that provide further information on the topic.- The listed articles are scientific studies related to vision and perception.\n",
            "- Each article explores different aspects of visual perception, such as discrimination of gratings, contrast detection, spatial summation effects, size-detecting mechanisms, spatial resolution, neural networks in the retina, probability summation, spatial-frequency channels, nonlinear spatial summation, and patterns of temporal interaction in the detection of gratings.\n",
            "- The studies involve experimentation and analysis to understand how the human visual system processes and perceives visual information.\n",
            "- The authors of the articles include various researchers and scientists in the field of vision and perception.\n",
            "- The articles were published in different years and in different scientific journals.\n"
          ]
        }
      ],
      "source": [
        "for x in save:\n",
        "  print(x)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
